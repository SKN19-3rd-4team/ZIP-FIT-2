import os
import time
import uuid
import psycopg2
from psycopg2 import extras
from pgvector.psycopg2 import register_vector
from dotenv import load_dotenv
from typing import Optional

# .env íŒŒì¼ ë¡œë“œëŠ” í•œë²ˆë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
load_dotenv()


## ğŸ› ï¸ DataBaseHandler: ì—°ê²° ê´€ë¦¬ (Context Manager)
# ì´ í´ë˜ìŠ¤ëŠ” ìˆœìˆ˜í•˜ê²Œ DB ì—°ê²°, ì»¤ì„œ ìƒì„±, íŠ¸ëœì­ì…˜(ì»¤ë°‹/ë¡¤ë°±) ê´€ë¦¬ ì—­í• ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
class DataBaseHandler:

    def __init__(self):
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ê°’ ë¡œë“œ (í•„ìš”í•˜ë‹¤ë©´)
        self.db_host = os.getenv("DB_HOST")
        self.db_port = os.getenv("DB_PORT")
        self.db_user = os.getenv("DB_USER")
        self.db_password = os.getenv("DB_PASSWORD")
        self.db_name = os.getenv("DB_NAME")
        self.conn = None
        self.cursor = None

    def set_connection(self, autocommit=True):
        """ì»¤ë„¥ì…˜ ìƒì„± ë° ì´ˆê¸°í™”."""
        try:
            if not self.conn or self.conn.closed:
                self.conn = psycopg2.connect(
                    host=self.db_host,
                    port=self.db_port,
                    database=self.db_name,
                    user=self.db_user,
                    password=self.db_password,
                )
            self.conn.autocommit = autocommit
            # pgvector ì‚¬ìš© ë“±ë¡
            register_vector(self.conn)
            return self.conn

        except psycopg2.Error as e:
            print(f"ğŸš¨ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
            raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ with ë¸”ë¡ì´ ì‹œì‘ë˜ì§€ ì•Šë„ë¡ í•¨

    def __enter__(self):
        """with ë¬¸ ì‹œì‘ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤. DB ì—°ê²°ì„ ì—´ê³  ì»¤ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # set_connection í˜¸ì¶œ ì‹œ autocommit=Trueê°€ ê¸°ë³¸ê°’ì´ë‚˜, __exit__ì—ì„œ commit/rollbackì„ ìœ„í•´ Falseë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        # ê¸°ì¡´ ì½”ë“œì—ì„œ autocommit=Trueë¡œ ì„¤ì •ë˜ì–´ ìˆì—ˆìœ¼ë¯€ë¡œ, ê·¸ ë¡œì§ì„ ìœ ì§€í•˜ë©´ì„œ íŠ¸ëœì­ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•´ conn.autocommit = False ì„¤ì •ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.
        # ë§Œì•½ with ë¸”ë¡ì—ì„œ íŠ¸ëœì­ì…˜ ê´€ë¦¬ë¥¼ ì›í•œë‹¤ë©´ set_connection(autocommit=False)ë¡œ ë³€ê²½í•˜ê³  __exit__ì˜ commit/rollbackì„ í™œì„±í™”í•´ì•¼ í•©ë‹ˆë‹¤.
        self.set_connection(autocommit=True)
        self.cursor = self.conn.cursor(
            cursor_factory=psycopg2.extras.RealDictCursor
        )  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ RealDictCursor ì‚¬ìš© ì¶”ì²œ
        return self.cursor

    def __exit__(self, exc_type, exc_value, traceback):
        """with ë¬¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤. ì»¤ë°‹ ë˜ëŠ” ë¡¤ë°± í›„ ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤."""
        if self.conn:
            if exc_type:
                # autocommit=Trueì¼ ê²½ìš° rollbackì€ íš¨ê³¼ê°€ ì—†ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ìœ ì§€
                print(f"ì˜¤ë¥˜ ë°œìƒ: {exc_value}. ë¡¤ë°±ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                self.conn.rollback()
            else:
                # autocommit=Trueì¼ ê²½ìš° commitì€ íš¨ê³¼ê°€ ì—†ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ìœ ì§€
                try:
                    self.conn.commit()
                except Exception as e:
                    print(f"ì»¤ë°‹ ì˜¤ë¥˜ ë°œìƒ: {e}")

            if self.cursor:
                self.cursor.close()
            # ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
            self.conn.close()


## ğŸš€ ZipFitDBHandler: ë¹„ì¦ˆë‹ˆìŠ¤/ë°ì´í„° ì²˜ë¦¬ ë¡œì§ ì „ë‹´
# ì´ í´ë˜ìŠ¤ëŠ” í…Œì´ë¸” ì •ì˜ ë° ë°ì´í„° ì‚½ì…/ë³‘í•© ë“± ì‹¤ì œ DB ì‘ì—… ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
class ZipFitDBHandler(DataBaseHandler):

    def __init__(self):
        # DataBaseHandlerì˜ __init__ì„ í˜¸ì¶œí•˜ì—¬ DB ì—°ê²° ì •ë³´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        super().__init__()

    def sample(self, batch_status, batch_id, batch_seq_list):
        self.set_connection()
        self.cursor = self.conn.cursor()

        try:
            pass
        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()

    # --- í…Œì´ë¸” ìƒì„± ë¡œì§ ---
    def set_default_tables(self, drop=False, sample_data=False):
        """ê¸°ë³¸ í…Œì´ë¸” ìƒì„± (ANNC_LH_TEMP, ANNC_ALL, ANNC_FILES, DOC_CHUNKS)"""
        try:
            # íŠ¸ëœì­ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•´ autocommit=Falseë¡œ ì—°ê²°
            self.set_connection(autocommit=False)
            self.cursor = self.conn.cursor()

            queries_execute = [
                # (ì„¤ëª…, í…Œì´ë¸”ëª…, CREATE ì¿¼ë¦¬, INSERT ì¿¼ë¦¬)
                (
                    "LH ê³µê³  í¬ë¡¤ë§ ë°°ì¹˜",
                    "ANNC_LH_TEMP",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_LH_TEMP (
                        BATCH_ID UUID NOT NULL, 
                        BATCH_SEQ INT NOT NULL, 
                        ANNC_URL TEXT, 
                        batch_status VARCHAR(10), 
                        BATCH_START_DTTM TIMESTAMPTZ, 
                        BATCH_END_DTTM TIMESTAMPTZ, 
                        ANNC_TYPE VARCHAR(50), 
                        ANNC_DTL_TYPE VARCHAR(20), 
                        ANNC_REGION VARCHAR(50), 
                        ANNC_PBLSH_DT VARCHAR(50), 
                        ANNC_DEADLINE_DT VARCHAR(50), 
                        ANNC_STATUS VARCHAR(20), 
                        LH_PAN_ID VARCHAR(50), 
                        LH_AIS_TP_CD VARCHAR(10), 
                        LH_UPP_AIS_TP_CD VARCHAR(10), 
                        LH_CCR_CNNT_SYS_DS_CD VARCHAR(10), 
                        LH_LS_SST VARCHAR(50), 
                        PRIMARY KEY (BATCH_ID, BATCH_SEQ)
                    );
                    """,
                    None,
                ),
                (
                    "ê³µê³  ì „ì²´ í…Œì´ë¸”",
                    "ANNC_ALL",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_ALL (
                        ANNC_ID BIGSERIAL PRIMARY KEY, 
                        ANNC_URL TEXT UNIQUE, 
                        CORP_CD VARCHAR(10), 
                        ANNC_TYPE VARCHAR(50), 
                        ANNC_DTL_TYPE VARCHAR(20), 
                        ANNC_REGION VARCHAR(50), 
                        ANNC_PBLSH_DT VARCHAR(50), 
                        ANNC_DEADLINE_DT VARCHAR(50), 
                        ANNC_STATUS VARCHAR(20), 
                        SERVICE_STATUS VARCHAR(20)
                    );
                    """,
                    """
                    INSERT INTO ANNC_ALL (
                            ANNC_URL,
                            CORP_CD,
                            ANNC_TYPE,
                            ANNC_DTL_TYPE,
                            ANNC_REGION,
                            ANNC_PBLSH_DT,
                            ANNC_DEADLINE_DT,
                            ANNC_STATUS,
                            SERVICE_STATUS
                        )
                    VALUES (
                            'http://annc.co.kr/1001',
                            'LH',
                            'ì£¼íƒê³µê¸‰',
                            'ì„ëŒ€',
                            'ì „êµ­',
                            '2025-11-01',
                            '2025-12-31',
                            'ì§„í–‰ì¤‘',
                            'Y'
                        ) ON CONFLICT (ANNC_URL) DO NOTHING;
                    """,  # ì¤‘ë³µ ì‚½ì… ë°©ì§€ë¥¼ ìœ„í•´ ON CONFLICT ì¶”ê°€
                ),
                (
                    "ê³µê³  íŒŒì¼",
                    "ANNC_FILES",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_FILES (
                        FILE_ID BIGSERIAL, 
                        ANNC_ID BIGSERIAL, 
                        FILE_NAME VARCHAR(500), 
                        FILE_TYPE VARCHAR(10), 
                        FILE_PATH VARCHAR(2000) UNIQUE, 
                        FILE_EXT VARCHAR(10), 
                        FILE_SIZE INT, 
                        PRIMARY KEY (FILE_ID, ANNC_ID), 
                        FOREIGN KEY (ANNC_ID) REFERENCES ANNC_ALL (ANNC_ID)
                    );
                    """,
                    """
                    INSERT INTO ANNC_FILES (
                            ANNC_ID,
                            FILE_NAME,
                            FILE_TYPE,
                            FILE_PATH,
                            FILE_EXT,
                            FILE_SIZE
                        )
                    VALUES (
                            (SELECT ANNC_ID FROM ANNC_ALL WHERE ANNC_URL = 'http://annc.co.kr/1001'),
                            '2025ë…„ ì£¼íƒê³µê¸‰ ê³µê³ ë¬¸.pdf',
                            'ê³µê³ ',
                            '/data/annc/1/file.pdf',
                            'pdf',
                            102400
                        ) ON CONFLICT (FILE_PATH) DO NOTHING;
                    """,  # ANNC_IDë¥¼ ì¡°íšŒí•˜ì—¬ ì‚½ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½, ì¤‘ë³µ ì‚½ì… ë°©ì§€ë¥¼ ìœ„í•´ ON CONFLICT ì¶”ê°€
                ),
                (
                    "ê³µê³  íŒŒì¼ ì²­í¬ ë²¡í„°",
                    "DOC_CHUNKS",
                    """
                    CREATE TABLE IF NOT EXISTS DOC_CHUNKS (
                        CHUNK_ID BIGSERIAL, 
                        FILE_ID BIGSERIAL, 
                        ANNC_ID BIGSERIAL, 
                        CHUNK_TEXT TEXT, 
                        PAGE_NUM SMALLINT, 
                        EMBEDDING VECTOR(1024), 
                        METADATA JSONB, 
                        PRIMARY KEY (CHUNK_ID), -- FILE_ID, ANNC_IDë¥¼ í¬í•¨í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì • (ì¼ë°˜ì ì¸ VEC DB íŒ¨í„´)
                        FOREIGN KEY (FILE_ID, ANNC_ID) REFERENCES ANNC_FILES (FILE_ID, ANNC_ID)
                    );
                    """,
                    None,  # ë²¡í„° ë°ì´í„° ìƒ˜í”Œì€ ë³µì¡í•˜ì—¬ ì£¼ì„ ì²˜ë¦¬ ìœ ì§€
                ),
            ]

            print(f"drop: {drop}, sample_data: {sample_data}")

            for title, table_name, create_query, insert_query in queries_execute:
                if drop:
                    # DROP TABLE IF EXISTS ANNC_LH_TEMP; ëŠ” ë„ˆë¬´ êµ¬ì²´ì ì´ë¯€ë¡œ í…Œì´ë¸”ëª… ë³€ìˆ˜ ì‚¬ìš©
                    self.cursor.execute(f"DROP TABLE IF EXISTS {table_name} CASCADE;")
                    print(f"ğŸ‘ table {title}-[{table_name}] dropped (CASCADE)")

                self.cursor.execute(create_query)
                print(f"âœ… table {title}-[{table_name}] created")

                if sample_data and insert_query:
                    self.cursor.execute(insert_query)
                    print(f"âœ¨ table {table_name} sample data inserted")

            self.conn.commit()  # íŠ¸ëœì­ì…˜ ì»¤ë°‹
        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            # set_connectionì—ì„œ connì´ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ì»¤ì„œ/ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()

    # --- ë°ì´í„° ì‚½ì…/ë³‘í•© ë¡œì§ ---
    def bulk_merge_lh(self, data_list, batch_size=100):

        self.set_connection()
        self.cursor = self.conn.cursor()

        try:

            # print('ì¿¼ë¦¬ ìƒì„±')
            # ë¡œì§ êµ¬í˜„
            # ...
            merge_query_template = """
            merge into annc_all as target using (
                values {values_sql_placeholder}
            ) as source (
                annc_url,
                annc_type,
                annc_dtl_type,
                annc_region,
                annc_pblsh_dt,
                annc_deadline_dt,
                annc_status
            ) on (target.annc_url = source.annc_url) -- annc_urlì„ ê¸°ì¤€ìœ¼ë¡œ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
            -- ì¼ì¹˜í•˜ëŠ” í–‰ì´ ìˆìœ¼ë©´ update
            when matched then
            update
            set annc_type = source.annc_type,
                annc_dtl_type = source.annc_dtl_type,
                annc_status = source.annc_status,
                annc_pblsh_dt = source.annc_pblsh_dt,
                annc_deadline_dt = source.annc_deadline_dt,
                service_status = 'PROCESSING'
                when not matched then
            insert (
                    annc_url,
                    corp_cd,
                    annc_type,
                    annc_dtl_type,
                    annc_region,
                    annc_pblsh_dt,
                    annc_deadline_dt,
                    annc_status,
                    service_status
                )
            values (
                    source.annc_url,
                    'LH',
                    source.annc_type,
                    source.annc_dtl_type,
                    source.annc_region,
                    source.annc_pblsh_dt,
                    source.annc_deadline_dt,
                    source.annc_status,
                    'PROCESSING'
                );
            """

            print("ì‹œì‘")
            for i in range(0, len(data_list), batch_size):
                batch_list = data_list[i : i + batch_size]

                values_to_insert = [
                    (
                        item["annc_url"],
                        item["annc_type"],
                        item["annc_dtl_type"],
                        item["annc_region"],
                        item["annc_pblsh_dt"],
                        item["annc_deadline_dt"],
                        item["annc_status"],
                    )
                    for item in batch_list
                ]

                # print(values_to_insert)

                # Psycopgë¥¼ ì‚¬ìš©í•˜ì—¬ VALUES êµ¬ë¬¸ì„ ì•ˆì „í•˜ê²Œ ìƒì„±
                # ì˜ˆ: ('url1', 'LH', ...), ('url2', 'LH', ...)
                value_placeholders = (
                    "(" + ", ".join(["%s"] * len(values_to_insert[0])) + ")"
                )

                # ëª¨ë“  VALUES íŠœí”Œì„ í•©ì¹œ ë‹¨ì¼ SQL ë¬¸ìì—´ ìƒì„±
                values_sql = ", ".join([value_placeholders] * len(values_to_insert))

                # ìµœì¢… ì¿¼ë¦¬ì— VALUES êµ¬ë¬¸ ì‚½ì…
                final_query = merge_query_template.replace(
                    "{values_sql_placeholder}", values_sql
                )

                # ëª¨ë“  ì²­í¬ ë°ì´í„°ì˜ ê°’ì„ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ í¼ì¹˜ê¸° (flat list)
                flat_values = [val for row in values_to_insert for val in row]

                # ì¿¼ë¦¬ ì‹¤í–‰
                self.cursor.execute(final_query, flat_values)
                print(f"âœ… {i}ë¶€í„° {i + batch_size - 1}ê¹Œì§€ {batch_size}ê±´ MERGE ì™„ë£Œ.")

        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            # set_connectionì—ì„œ connì´ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ ì»¤ì„œ/ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()

    def bulk_insert_lh_temp(self, data_list):

        is_succed = False
        new_uuid = ""

        # DataBaseHandlerì˜ with êµ¬ë¬¸ì„ ìƒì†ë°›ì•„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # with self.conn.cursor() as self.cursor: ëŒ€ì‹  with self.cursor: ì‚¬ìš© (ë” ê°„ê²°í•œ ì‚¬ìš©ì„ ìœ„í•´ __enter__ / __exit__ ìˆ˜ì • ê°€ëŠ¥)
        try:
            # set_connection(autocommit=True)ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ íŠ¸ëœì­ì…˜ ìë™ ì»¤ë°‹ ëª¨ë“œë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
            self.set_connection(autocommit=True)
            self.cursor = self.conn.cursor()

            insert_query = """
                INSERT INTO ANNC_LH_TEMP (
                        BATCH_ID,
                        BATCH_SEQ,
                        ANNC_URL,
                        batch_status,
                        BATCH_START_DTTM,
                        BATCH_END_DTTM,
                        ANNC_TYPE,
                        ANNC_DTL_TYPE,
                        ANNC_REGION,
                        ANNC_PBLSH_DT,
                        ANNC_DEADLINE_DT,
                        ANNC_STATUS,
                        LH_PAN_ID,
                        LH_AIS_TP_CD,
                        LH_UPP_AIS_TP_CD,
                        LH_CCR_CNNT_SYS_DS_CD,
                        LH_LS_SST
                    )
                VALUES %s
            """

            new_uuid = str(uuid.uuid4())
            current_dttm = time.strftime(
                "%Y-%m-%d %H:%M:%S", time.gmtime()
            )  # ì‹œì‘ ì‹œê°„ ê¸°ë¡ì„ ìœ„í•´ ì¶”ê°€

            processed_data = []
            for idx, item in enumerate(data_list, 1):
                # data_listì˜ ìš”ì†Œê°€ ANNC_URLë¶€í„° ì‹œì‘í•œë‹¤ê³  ê°€ì •
                new_row = (
                    new_uuid,  # BATCH_ID
                    idx,  # BATCH_SEQ
                    item[0],  # ANNC_URL
                    "READY",  # batch_status (ê³ ì •)
                    current_dttm,  # BATCH_START_DTTM (í˜„ì¬ ì‹œê°„)
                    None,  # BATCH_END_DTTM (NULL)
                    item[1],  # ANNC_TYPE
                    item[2],  # ANNC_DTL_TYPE
                    item[3],  # ANNC_REGION
                    item[4],  # ANNC_PBLSH_DT
                    item[5],  # ANNC_DEADLINE_DT
                    item[6],  # ANNC_STATUS
                    item[7],  # LH_PAN_ID
                    item[8],  # LH_AIS_TP_CD
                    item[9],  # LH_UPP_AIS_TP_CD
                    item[10],  # LH_CCR_CNNT_SYS_DS_CD
                    item[11],  # LH_LS_SST
                )
                processed_data.append(new_row)

            start_time = time.time()

            # extras.execute_valuesë¥¼ ì‚¬ìš©í•˜ì—¬ ë²Œí¬ ì‚½ì… ì‹¤í–‰
            extras.execute_values(self.cursor, insert_query, processed_data)

            # autocommit=True ì´ë¯€ë¡œ conn.commit()ì´ í•„ìš” ì—†ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.
            # self.conn.commit()

            end_time = time.time()
            print(f"âœ… Psycopg2 ë²Œí¬ ì‚½ì… ì„±ê³µ! {len(data_list)}ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ.")
            print(f" Â  ì†Œìš” ì‹œê°„: {end_time - start_time:.4f} ì´ˆ")

            is_succed = True

            # print(f" ì™„ë£Œ")

        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()

            return is_succed, new_uuid

    def get_lh_temp(self, uuid, status, dictionay=False):
        self.set_connection(autocommit=True)
        self.cursor = (
            self.conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            if dictionay
            else self.conn.cursor()
        )

        sql_query = """
            select alt.batch_id,
                alt.batch_seq,
                alt.annc_url,
                alt.batch_status,
                alt.batch_start_dttm,
                alt.batch_end_dttm,
                alt.annc_type,
                alt.annc_dtl_type,
                alt.annc_region,
                alt.annc_pblsh_dt,
                alt.annc_deadline_dt,
                alt.annc_status,
                alt.lh_pan_id,
                alt.lh_ais_tp_cd,
                alt.lh_upp_ais_tp_cd,
                alt.lh_ccr_cnnt_sys_ds_cd,
                alt.lh_ls_sst
            from annc_lh_temp alt
            where alt.batch_id = %s
            and alt.batch_status = %s
        """

        self.cursor.execute(sql_query, (uuid, status))  # ğŸ‘ˆ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©

        return self.cursor.fetchall()

    def get_lh_temp_for_batch(self, uuid, dictionay=False):
        self.set_connection(autocommit=True)
        self.cursor = (
            self.conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            if dictionay
            else self.conn.cursor()
        )

        # 1. ì¿¼ë¦¬ ë‚´ì—ì„œ ë³€ìˆ˜ê°€ ë“¤ì–´ê°ˆ ìë¦¬ì— í”Œë ˆì´ìŠ¤í™€ë”(ì¼ë°˜ì ìœ¼ë¡œ %s ë˜ëŠ” ?)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        # PostgreSQL/MySQL ë“±: %s ì‚¬ìš©
        sql_query = """
            select distinct *
            from (
                select alt.batch_id,
                    alt.batch_seq,
                    alt.annc_url,
                    alt.batch_status,
                    alt.batch_start_dttm,
                    alt.batch_end_dttm,
                    alt.annc_type,
                    alt.annc_dtl_type,
                    alt.annc_region,
                    alt.annc_pblsh_dt,
                    alt.annc_deadline_dt,
                    alt.annc_status,
                    alt.lh_pan_id,
                    alt.lh_ais_tp_cd,
                    alt.lh_upp_ais_tp_cd,
                    alt.lh_ccr_cnnt_sys_ds_cd,
                    alt.lh_ls_sst
                from annc_lh_temp alt
                where alt.batch_id = %s
                    and not exists(
                        select *
                        from annc_all aa
                        where aa.annc_url = alt.annc_url
                    )
                    and alt.annc_type not in ('ê¸°íƒ€')
                union all
                select alt.batch_id,
                    alt.batch_seq,
                    alt.annc_url,
                    alt.batch_status,
                    alt.batch_start_dttm,
                    alt.batch_end_dttm,
                    alt.annc_type,
                    alt.annc_dtl_type,
                    alt.annc_region,
                    alt.annc_pblsh_dt,
                    alt.annc_deadline_dt,
                    alt.annc_status,
                    alt.lh_pan_id,
                    alt.lh_ais_tp_cd,
                    alt.lh_upp_ais_tp_cd,
                    alt.lh_ccr_cnnt_sys_ds_cd,
                    alt.lh_ls_sst
                from annc_lh_temp alt
                    join annc_all aa on alt.annc_url = aa.annc_url
                where alt.batch_id = %s
                    and (alt.annc_pblsh_dt != aa.annc_pblsh_dt
                    or alt.annc_pblsh_dt != aa.annc_pblsh_dt
                    or alt.annc_status != aa.annc_status)
                    and alt.annc_type not in ('ê¸°íƒ€')
                    
            ) a
        """

        # 2. execute()ì˜ ë‘ ë²ˆì§¸ ì¸ìˆ˜ì— íŠœí”Œ í˜•íƒœë¡œ ë³€ìˆ˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        # í”Œë ˆì´ìŠ¤í™€ë” ìˆœì„œëŒ€ë¡œ ë³€ìˆ˜(uuid)ë¥¼ ë‚˜ì—´í•©ë‹ˆë‹¤.
        self.cursor.execute(sql_query, (uuid, uuid))  # ğŸ‘ˆ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©

        return self.cursor.fetchall()

    def set_batch_status(self, batch_status, batch_id, batch_seq_list):
        self.set_connection()
        self.cursor = self.conn.cursor()

        update_query = """
            update annc_lh_temp
            set batch_status = %s
            where batch_id = %s
            and batch_seq in %s
        """

        try:


            params = (batch_status, batch_id, tuple(batch_seq_list))

            self.cursor.execute(update_query, params)

        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback()  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()

    def get_annc_all(
        self,
        corp_cd,
        annc_url: Optional[str] = None,
        annc_status: Optional[str] = None,
        annc_type: Optional[str] = None,
        dictionay: Optional[bool] = False,
    ):
        self.set_connection()
        self.cursor = (
            self.conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            if dictionay
            else self.conn.cursor()
        )

        sql_query = """
            select *
            from annc_all
            where corp_cd = %s
            and (%s IS NULL OR annc_url = %s)
            and (%s IS NULL OR annc_status = %s)
            and (%s IS NULL OR annc_type = %s)
            """

        self.cursor.execute(sql_query, (corp_cd, annc_url, annc_url, annc_status, annc_status, annc_type, annc_type))  # ğŸ‘ˆ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©

        return self.cursor.fetchall()
    

    def remove_annc_file(self, annc_id: Optional[int]|Optional[list]):
        self.set_connection()
        self.cursor = self.conn.cursor()

        update_query = """
            delete from annc_files
            where annc_id in %s
        """

        annc_id_list = (annc_id) if type(annc_id) == int else tuple(annc_id)

        try:

            params = (annc_id_list)

            self.cursor.execute(update_query, params)
        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback() # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()


    def insert_annc_file(self, annc_files):
        self.set_connection()
        self.cursor = self.conn.cursor()

        insert_query = """
            insert into annc_files
            (
                file_id,
                annc_id,
                file_name,
                file_type,
                file_path,
                file_ext,
                file_size
            )
            values %s
        """

        try:

            extras.execute_values(self.cursor, insert_query, annc_files)
        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback() # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                if self.cursor and not self.cursor.closed:
                    self.cursor.close()
                if not self.conn.closed:
                    self.conn.close()
