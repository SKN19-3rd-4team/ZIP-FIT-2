from dotenv import load_dotenv
import os, time
import psycopg2
from psycopg2 import extras
from pgvector.psycopg2 import register_vector
import numpy as np
import uuid



load_dotenv()

class DataBaseHandler():

    def __init__(self):
        self.db_host = None
        self.db_port = None
        self.db_user = None
        self.db_password = None
        self.db_name = None
        self.conn = None

    def set_connection(self, autocommit=True):
        """
        ì»¤ë„¥ì…˜ ìƒì„±
        """
        self.db_host = self.db_host if self.db_host else os.getenv('DB_HOST')
        self.db_port = self.db_port if self.db_port else os.getenv('DB_PORT')
        self.db_user = self.db_user if self.db_user else os.getenv('DB_USER')
        self.db_password = self.db_password if self.db_password else os.getenv('DB_PASSWORD')
        self.db_name = self.db_name if self.db_name else os.getenv('DB_NAME')

        try:
            if not self.conn:
                self.conn = psycopg2.connect(
                host=self.db_host,
                port=self.db_port,
                database=self.db_name,
                user=self.db_user,
                password=self.db_password
            )
            self.conn.autocommit = True
            register_vector(self.conn)

        except psycopg2.Error as e:
            # ì—°ê²° ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì•Œë¦¼
            print(f"ğŸš¨ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}") 
            # ì—°ê²° ê°ì²´ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ conn.close() ë“±ì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì˜ˆì™¸ ë°œìƒ
            raise # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ with ë¸”ë¡ì´ ì‹œì‘ë˜ì§€ ì•Šë„ë¡ í•¨


    def set_default_tables(self, drop=False, sample_data=False):
        try:
            self.set_connection(False)
            self.cursor = self.conn.cursor()


            queries_execute = []

            queries_execute.append(
                (
                    "LH ê³µê³  í¬ë¡¤ë§ ë°°ì¹˜",
                    "ANNC_LH_TEMP",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_LH_TEMP (
                        BATCH_ID UUID NOT NULL,               -- ë°°ì¹˜ ID (UUID íƒ€ì…)
                        BATCH_SEQ INT NOT NULL,               -- ë°°ì¹˜ SEQ
                        ANNC_URL TEXT,                        -- ê³µê³  URL (TEXT íƒ€ì…)
                        BATCH_STATUS_CD VARCHAR(10),          -- ë°°ì¹˜ ìƒíƒœ ì½”ë“œ (VARCHAR(10))
                        BATCH_START_DTTM TIMESTAMPTZ,         -- ë°°ì¹˜ ë“±ë¡ ì‹œê°„ (TIMESTAMPTZ íƒ€ì…, ì‹œê°„ëŒ€ í¬í•¨)
                        BATCH_END_DTTM TIMESTAMPTZ,           -- ë°°ì¹˜ ì™„ë£Œ ì‹œê°„ (TIMESTAMPTZ íƒ€ì…, ì‹œê°„ëŒ€ í¬í•¨)
                        ANNC_TYPE VARCHAR(50),                -- ê³µê³  ìœ í˜• (VARCHAR(50))
                        ANNC_REGION VARCHAR(50),              -- ì§€ì—­ (VARCHAR(50))
                        ANNC_PBLSH_DT VARCHAR(50),            -- ê²Œì‹œì¼ (VARCHAR(50))
                        ANNC_DEADLINE_DT VARCHAR(50),         -- ë§ˆê°ì¼ (VARCHAR(50))
                        ANNC_STATUS VARCHAR(20),              -- ê³µê³  ìƒíƒœ (VARCHAR(20))
                        LH_PAN_ID VARCHAR(50),                -- ê³µê³  ì‹ë³„ ID (VARCHAR(50))
                        LH_AIS_TP_CD VARCHAR(10),             -- ê³µê³  ìœ í˜• ì½”ë“œ (VARCHAR(10))
                        LH_UPP_AIS_TP_CD VARCHAR(10),         -- ìƒìœ„ ê³µê³  ìœ í˜• ì½”ë“œ (VARCHAR(10))
                        LH_CCR_CNNT_SYS_DS_CD VARCHAR(10),    -- ì—°ê³„ ì‹œìŠ¤í…œ êµ¬ë¶„ ì½”ë“œ (VARCHAR(10))
                        LH_LS_SST VARCHAR(50),                -- ëª©ë¡ ìƒì˜ ìƒíƒœ/ìˆœì„œ (VARCHAR(50)),
                        PRIMARY KEY (BATCH_ID, BATCH_SEQ)     -- ê¸°ë³¸ í‚¤: BATCH_IDì™€ BATCH_SEQì˜ ë³µí•© í‚¤
                    );
                    """,
                    None
                )
            )

            queries_execute.append(
                (
                    "ê³µê³  ì „ì²´ í…Œì´ë¸”",
                    "ANNC_ALL",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_ALL (
                        ANNC_ID BIGSERIAL PRIMARY KEY,      -- ê³µê³  ID (BIGSERIAL, ê¸°ë³¸ í‚¤)
                        ANNC_URL TEXT,                      -- ê³µê³  URL (TEXT)
                        CORP_CD VARCHAR(10),                -- ê³µì‚¬ ì½”ë“œ (VARCHAR(10))
                        ANNC_TYPE VARCHAR(50),              -- ê³µê³  ìœ í˜• (VARCHAR(50))
                        ANNC_REGION VARCHAR(50),            -- ì§€ì—­ (VARCHAR(50))
                        ANNC_PBLSH_DT VARCHAR(50),          -- ê²Œì‹œì¼ (VARCHAR(50))
                        ANNC_DEADLINE_DT VARCHAR(50),       -- ë§ˆê°ì¼ (VARCHAR(50))
                        ANNC_STATUS VARCHAR(20),            -- ê³µê³  ìƒíƒœ (VARCHAR(20))
                        SERVICE_STATUS VARCHAR(20)          -- ì„œë¹„ìŠ¤ ìƒíƒœ (VARCHAR(20))
                    );
                    """,                    
                    """
                    INSERT INTO ANNC_ALL (
                        ANNC_URL, CORP_CD, ANNC_TYPE, ANNC_REGION, ANNC_PBLSH_DT, ANNC_DEADLINE_DT, ANNC_STATUS, SERVICE_STATUS
                    ) VALUES (
                        'http://annc.co.kr/1001', 'LH', 'ì£¼íƒê³µê¸‰', 'ì „êµ­', '2025-11-01', '2025-12-31', 'ì§„í–‰ì¤‘', 'Y'
                    );
                    """
                )
            )


            queries_execute.append(
                (
                    "ê³µê³  íŒŒì¼",
                    "ANNC_FILES",
                    """
                    CREATE TABLE IF NOT EXISTS ANNC_FILES (
                        FILE_ID BIGSERIAL,                  -- ê³µê³  íŒŒì¼ ID (BIGSERIAL)
                        ANNC_ID BIGSERIAL,                  -- ê³µê³  ID (BIGSERIAL, ANNC_ALL ì°¸ì¡°)
                        FILE_NAME VARCHAR(500),             -- ê³µê³  íŒŒì¼ëª… (VARCHAR(500))
                        FILE_TYPE VARCHAR(10),              -- ê³µê³  íŒŒì¼ ìœ í˜• (VARCHAR(10))
                        FILE_PATH VARCHAR(2000),            -- ê³µê³  íŒŒì¼ ê²½ë¡œ (VARCHAR(2000))
                        FILE_EXT VARCHAR(10),               -- ê³µê³  íŒŒì¼ í™•ì¥ì (VARCHAR(10))
                        FILE_SIZE INT,                      -- ê³µê³  íŒŒì¼ ì‚¬ì´ì¦ˆ (INT)
                        IS_VECTORIZED BOOLEAN,              -- ì„ë² ë”© ì™„ë£Œ (BOOLEAN)
                        PRIMARY KEY (FILE_ID, ANNC_ID),     -- ë³µí•© ê¸°ë³¸ í‚¤
                        FOREIGN KEY (ANNC_ID) REFERENCES ANNC_ALL (ANNC_ID)
                    );
                    """,
                    """
                    INSERT INTO ANNC_FILES (
                        ANNC_ID, FILE_NAME, FILE_TYPE, FILE_PATH, FILE_EXT, FILE_SIZE, IS_VECTORIZED
                    ) VALUES (
                        1, -- ANNC_ALL í…Œì´ë¸”ì— ì‚½ì…ëœ ê³µê³ ì˜ ID (ì˜ˆ: 1)
                        '2025ë…„ ì£¼íƒê³µê¸‰ ê³µê³ ë¬¸.pdf', 'ê³µê³ ', '/data/annc/1/file.pdf', 'pdf', 102400, FALSE
                    );
                    """
                )
            )


            queries_execute.append(
                (
                    "ê³µê³  íŒŒì¼ ì²­í¬ ë²¡í„°",
                    "DOC_CHUNKS",
                    """
                    CREATE TABLE IF NOT EXISTS DOC_CHUNKS (
                        CHUNK_ID BIGSERIAL,                 -- ì²­í¬ ID (BIGSERIAL)
                        FILE_ID BIGSERIAL,                  -- ê³µê³  íŒŒì¼ ID (BIGSERIAL, ANNC_FILES ì°¸ì¡°)
                        ANNC_ID BIGSERIAL,                  -- ê³µê³  ID (BIGSERIAL, ANNC_FILES ì°¸ì¡°)
                        CHUNK_TEXT TEXT,                    -- ì²­í¬ í…ìŠ¤íŠ¸ (TEXT)
                        PAGE_NUM SMALLINT,                  -- í˜ì´ì§€ ë²ˆí˜¸ (SMALLINT)
                        EMBEDDING VECTOR(1024),             -- ì„ë² ë”© ë²¡í„° (VECTOR(1024))
                        METADATA JSONB,                     -- ë©”íƒ€ë°ì´í„° (JSONB)
                        PRIMARY KEY (CHUNK_ID, FILE_ID, ANNC_ID), -- ë³µí•© ê¸°ë³¸ í‚¤
                        FOREIGN KEY (FILE_ID, ANNC_ID) REFERENCES ANNC_FILES (FILE_ID, ANNC_ID)
                    );
                    """,
                    None
                    # """
                    # INSERT INTO DOC_CHUNKS (
                    #     FILE_ID, ANNC_ID, CHUNK_TEXT, PAGE_NUM, EMBEDDING, METADATA
                    # ) VALUES (
                    #     1, -- ANNC_FILES í…Œì´ë¸”ì— ì‚½ì…ëœ íŒŒì¼ ID (ì˜ˆ: 1)
                    #     1, -- ANNC_ALL í…Œì´ë¸”ì— ì‚½ì…ëœ ê³µê³  ID (ì˜ˆ: 1)
                    #     'ì²­í¬ 1: ì£¼íƒ ê³µê¸‰ì— ëŒ€í•œ ìì„¸í•œ ê·œì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.',
                    #     1,
                    #     '[0.1, 0.2, 0.3, ..., 0.9, 1.0]', -- 1024ì°¨ì› ë²¡í„°ì˜ ê°„ëµí•œ ì˜ˆì‹œ
                    #     '{"source": "paragraph_1", "category": "rule"}'::jsonb
                    # );
                    # """
                )
            )

            print(f'drop: {drop}, sample_data: {sample_data}')

            for title, table_name, create_query, insert_query in queries_execute:
                if drop:
                    self.cursor.execute(f"DROP TABLE IF EXISTS ANNC_LH_TEMP;")
                    print(f"ğŸ‘ table {title}-[{table_name}] dropped")
                
                self.cursor.execute(create_query)
                print(f"âœ… table {title}-[{table_name}] created")

                if sample_data and insert_query:
                    self.cursor.execute(insert_query)


            self.conn.commit()
        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback() # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                self.cursor.close()
                self.conn.close() 

    def bulk_merge_lh(self, data_list, batch_size=100):
        ...
    
    def bulk_insert_lh_temp(self, data_list):

        is_succed = False
        new_uuid = ""

        try:
            self.set_connection()
            self.cursor = self.conn.cursor()

            insert_query = """
                INSERT INTO ANNC_LH_TEMP (BATCH_ID, BATCH_SEQ, ANNC_URL, BATCH_STATUS_CD, BATCH_START_DTTM, BATCH_END_DTTM, ANNC_TYPE, ANNC_REGION, ANNC_PBLSH_DT, ANNC_DEADLINE_DT, ANNC_STATUS, LH_PAN_ID, LH_AIS_TP_CD, LH_UPP_AIS_TP_CD, LH_CCR_CNNT_SYS_DS_CD, LH_LS_SST)
                VALUES %s
            """

            new_uuid = str(uuid.uuid4())

            data_list = [
                (new_uuid, idx, *item)
                for idx, item in enumerate(data_list, 1)
            ]

            processed_data = []
            for item in data_list:
                new_row = (
                    item[0],  # BATCH_ID
                    item[1],  # BATCH_SEQ
                    item[2],  # ANNC_URL
                    'READY',  # BATCH_STATUS_CD (ê³ ì •)
                    None,     # BATCH_START_DTTM (ê³ ì •)
                    None,     # BATCH_END_DTTM (ê³ ì • - NULL)
                    item[3],  # ANNC_TYPE
                    item[4],  # ANNC_REGION
                    item[5],  # ANNC_PBLSH_DT
                    item[6],  # ANNC_DEADLINE_DT
                    item[7],  # ANNC_STATUS
                    item[8],  # LH_PAN_ID
                    item[9],  # LH_AIS_TP_CD
                    item[10], # LH_UPP_AIS_TP_CD
                    item[11], # LH_CCR_CNNT_SYS_DS_CD
                    item[12]  # LH_LS_SST
                )
                processed_data.append(new_row)

            start_time = time.time()
        
            # 3. execute_many()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²Œí¬ ì‚½ì… ì‹¤í–‰
            # ì´ í•¨ìˆ˜ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ íšŸìˆ˜ë¥¼ ìµœì†Œí™”í•˜ì—¬ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            extras.execute_values(self.cursor, insert_query, processed_data)
            
            # 4. íŠ¸ëœì­ì…˜ ì»¤ë°‹
            self.conn.commit()
            
            end_time = time.time()
            print(f"âœ… Psycopg2 ë²Œí¬ ì‚½ì… ì„±ê³µ! {len(data_list)}ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ.")
            print(f"   ì†Œìš” ì‹œê°„: {end_time - start_time:.4f} ì´ˆ")

            is_succed = True

        except (Exception, psycopg2.Error) as error:
            print(f"âŒ Psycopg2 DB ì—ëŸ¬ ë°œìƒ: {error}")
            if self.conn:
                self.conn.rollback() # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡¤ë°±
        finally:
            if self.conn:
                self.cursor.close()
                self.conn.close()
            return is_succed, new_uuid



    def __enter__(self):
        """
        with ë¬¸ ì‹œì‘ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤. DB ì—°ê²°ì„ ì—´ê³  ì»¤ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            psycopg2.Cursor: DB ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì»¤ì„œ ê°ì²´
        """

        self.set_connection()
        self.cursor = self.conn.cursor()
        return self.cursor
    
    def __exit__(self, exc_type, exc_value, traceback):
        """
        with ë¬¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤. ì»¤ë°‹ ë˜ëŠ” ë¡¤ë°± í›„ ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
        Args:
        exc_type, exc_value, traceback: ë°œìƒí•œ ì˜ˆì™¸ ì •ë³´
        """
        if exc_type:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {exc_value}. ë¡¤ë°±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            self.conn.rollback()
        else:
            # ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ë³€ê²½ ì‚¬í•­ì„ ì»¤ë°‹í•©ë‹ˆë‹¤.
            self.conn.commit()

        # ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
        if self.conn:
            self.conn.close()

class DatabaseExecuteSamples:
    """
    DataBaseHandlerë¥¼ ì‚¬ìš©í•˜ì—¬ PostgreSQLì—ì„œ CRUD ë° JOIN ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ”
    ìƒ˜í”Œ ë©”ì„œë“œë¥¼ ëª¨ì•„ ë†“ì€ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """

    def create_tables(self):
        """ë¬¸ì„œ ë° ì‘ì„±ì í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("--- 1. í…Œì´ë¸” ìƒì„± ì‹œì‘ ---")
        try:
            with DataBaseHandler() as cursor:
                # authors í…Œì´ë¸” ìƒì„±
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS authors (
                        author_id SERIAL PRIMARY KEY,
                        name VARCHAR(100) NOT NULL,
                        email VARCHAR(100) UNIQUE
                    );
                """)

                # documents í…Œì´ë¸” ìƒì„± (pgvectorì˜ vector(3) íƒ€ì… ì‚¬ìš©)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS documents (
                        doc_id SERIAL PRIMARY KEY,
                        author_id INTEGER REFERENCES authors(author_id),
                        title VARCHAR(255) NOT NULL,
                        content TEXT,
                        vector vector(3) 
                    );
                """)
                print("í…Œì´ë¸” 'authors' ë° 'documents' ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    # ---

    def insert_data(self):
        """ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚½ì…í•˜ê³  ë²¡í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        print("\n--- 2. ë°ì´í„° ì‚½ì… ì‹œì‘ ---")
        # ì˜ˆì‹œ ë²¡í„° ë°ì´í„° (ì°¨ì›ì€ 3ìœ¼ë¡œ ê°€ì •)
        vector_data_1 = np.array([0.1, 0.2, 0.3])
        vector_data_2 = np.array([0.4, 0.5, 0.6])

        try:
            with DataBaseHandler() as cursor:
                # ì‘ì„±ì ë°ì´í„° ì‚½ì…
                cursor.execute(
                    "INSERT INTO authors (name, email) VALUES (%s, %s) RETURNING author_id;",
                    ('ê¹€ì§€ìˆ˜', 'jisoo@example.com')
                )
                # ì‚½ì…ëœ author_idë¥¼ ê°€ì ¸ì˜´
                author_id_1 = cursor.fetchone()[0] 

                cursor.execute(
                    "INSERT INTO authors (name, email) VALUES (%s, %s) RETURNING author_id;",
                    ('ë°•í˜„ìš°', 'hyeonwoo@example.com')
                )
                author_id_2 = cursor.fetchone()[0]
                
                # ë¬¸ì„œ ë°ì´í„° ì‚½ì… (ë²¡í„° ë°ì´í„° í¬í•¨)
                cursor.execute(
                    "INSERT INTO documents (author_id, title, content, vector) VALUES (%s, %s, %s, %s);",
                    (author_id_1, 'íŒŒì´ì¬ Context Manager', 'DB ì—°ê²° ê´€ë¦¬ì˜ íš¨ìœ¨ì„±', vector_data_1)
                )
                cursor.execute(
                    "INSERT INTO documents (author_id, title, content, vector) VALUES (%s, %s, %s, %s);",
                    (author_id_2, 'ë²¡í„° ê²€ìƒ‰ ê°œìš”', 'pgvectorì˜ ì‘ë™ ë°©ì‹ì— ëŒ€í•œ ì„¤ëª…', vector_data_2)
                )
                print(f"ì‘ì„±ì 2ëª… ë° ë¬¸ì„œ 2ê°œ ì‚½ì… ì™„ë£Œ.")
        except Exception as e:
            print(f"ë°ì´í„° ì‚½ì… ì˜¤ë¥˜: {e}")
            
    # ---

    def select_query(self, doc_title):
        """íŠ¹ì • ì œëª©ì˜ ë¬¸ì„œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        print(f"\n--- 3. SELECT ì¿¼ë¦¬: '{doc_title}' ---")
        try:
            with DataBaseHandler() as cursor:
                cursor.execute(
                    "SELECT doc_id, title, content FROM documents WHERE title = %s;",
                    (doc_title,)
                )
                result = cursor.fetchone()
                if result:
                    print(f"ì¡°íšŒ ê²°ê³¼: ID={result[0]}, ì œëª©={result[1]}, ë‚´ìš©={result[2]}")
                else:
                    print(f"'{doc_title}' ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì¡°íšŒ ì˜¤ë¥˜: {e}")

    # ---

    def join_query(self):
        """JOIN ì¿¼ë¦¬ë¡œ ë¬¸ì„œì™€ ì‘ì„±ì ì •ë³´ë¥¼ í•¨ê»˜ ì¡°íšŒí•©ë‹ˆë‹¤."""
        print("\n--- 4. JOIN ì¿¼ë¦¬ (ë¬¸ì„œ + ì‘ì„±ì) ---")
        try:
            with DataBaseHandler() as cursor:
                cursor.execute("""
                    SELECT 
                        d.title, 
                        a.name AS author_name,
                        a.email 
                    FROM documents d
                    JOIN authors a ON d.author_id = a.author_id;
                """)
                
                results = cursor.fetchall()
                for row in results:
                    print(f"ì œëª©: {row[0]}, ì‘ì„±ì: {row[1]}, ì´ë©”ì¼: {row[2]}")
        except Exception as e:
            print(f"JOIN ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")

    # ---

    def update_query(self, doc_title, new_content):
        """íŠ¹ì • ë¬¸ì„œì˜ ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
        print(f"\n--- 5. UPDATE ì¿¼ë¦¬: '{doc_title}' ---")
        try:
            with DataBaseHandler() as cursor:
                cursor.execute(
                    "UPDATE documents SET content = %s WHERE title = %s;",
                    (new_content, doc_title)
                )
                print(f"'{doc_title}' ë¬¸ì„œ ë‚´ìš©ì´ '{new_content}'ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

    # ---

    def delete_query(self, doc_title):
        """íŠ¹ì • ì œëª©ì˜ ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
        print(f"\n--- 6. DELETE ì¿¼ë¦¬: '{doc_title}' ---")
        try:
            with DataBaseHandler() as cursor:
                cursor.execute(
                    "DELETE FROM documents WHERE title = %s;",
                    (doc_title,)
                )
                print(f"'{doc_title}' ë¬¸ì„œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì‚­ì œ ì˜¤ë¥˜: {e}")

    # ---

    def drop_tables(self):
        """ì˜ˆì œ í…Œì´ë¸”ì„ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤."""
        print("\n--- 7. í…Œì´ë¸” ì‚­ì œ ì‹œì‘ ---")
        try:
            with DataBaseHandler() as cursor:
                # ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ë•Œë¬¸ì— documentsë¥¼ ë¨¼ì € ì‚­ì œ
                cursor.execute("DROP TABLE IF EXISTS documents;")
                cursor.execute("DROP TABLE IF EXISTS authors;")
                print("í…Œì´ë¸” 'documents' ë° 'authors' ì‚­ì œ ì™„ë£Œ.")
        except Exception as e:
            print(f"í…Œì´ë¸” ì‚­ì œ ì˜¤ë¥˜: {e}")