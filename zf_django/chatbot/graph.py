# chatbot/graph.py
"""
LangGraph ê¸°ë°˜ ì£¼íƒ ê³µê³  ì±—ë´‡ (V7)
- RDB í•„í„° + RAG ê²€ìƒ‰ í†µí•©
- ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ë° ë¹„êµ ê¸°ëŠ¥
- ì›¹ ê²€ìƒ‰ ì—°ë™
"""
import json
import re
import time
from datetime import date
from typing import TypedDict, List, Optional, Dict, Any

from langgraph.graph import StateGraph, END
from openai import OpenAI
from decouple import config

from .services import AnncAllService, DocChunkService

client = OpenAI(api_key=config('OPENAI_API_KEY'))

# Tavily (ì„ íƒì )
TAVILY_API_KEY = config('TAVILY_API_KEY', default=None)
TAVILY_AVAILABLE = False
tavily_client = None

if TAVILY_API_KEY:
    try:
        from tavily import TavilyClient
        tavily_client = TavilyClient(api_key=TAVILY_API_KEY)
        TAVILY_AVAILABLE = True
    except ImportError:
        pass


# =============================================================================
# ì„¤ì •
# =============================================================================
class ChatbotConfig:
    LLM_MODEL = "gpt-4o-mini"
    EMBEDDING_MODEL = "text-embedding-3-small"
    MAX_HISTORY_TURNS = 10
    MAX_SEARCH_HISTORY = 5
    RAG_TOP_K = 15

    _cache: Dict[str, Any] = {}
    _cache_ttl = 300

    @classmethod
    def _load_cache(cls):
        if cls._cache.get("time") and (time.time() - cls._cache["time"]) < cls._cache_ttl:
            return
        from .models import AnncAll
        active = AnncAll.objects.filter(service_status='OPEN')
        cls._cache = {
            "regions": list(active.values_list('annc_region', flat=True).distinct()),
            "statuses": list(active.values_list('annc_status', flat=True).distinct()),
            "types": list(active.values_list('annc_type', flat=True).distinct()),
            "dtl_types": list(active.values_list('annc_dtl_type', flat=True).distinct()),
            "time": time.time()
        }

    @classmethod
    def get(cls, key: str) -> list:
        cls._load_cache()
        return cls._cache.get(key, [])


# =============================================================================
# ì˜ë„ ì •ì˜
# =============================================================================
class Intent:
    SEARCH = "search"      # ê³µê³  ê²€ìƒ‰ (ì‹ ê·œ/ì¶”ê°€/ë³µì›)
    SELECT = "select"      # ëª©ë¡ì—ì„œ ì„ íƒ
    DETAIL = "detail"      # ìƒì„¸ ì§ˆë¬¸
    COMPARE = "compare"    # ë¹„êµ
    CHAT = "chat"          # ì¼ë°˜ ëŒ€í™”/ì›¹ ê²€ìƒ‰


# =============================================================================
# State ì •ì˜
# =============================================================================
class GraphState(TypedDict):
    question: str
    chat_history: List[dict]
    # ì˜ë„ ê´€ë ¨
    intent: str
    intent_data: dict
    # ê²€ìƒ‰ ê´€ë ¨
    search_history: List[dict]  # [{query, anncs, timestamp}]
    prev_anncs: List[dict]
    selected_annc: Optional[dict]
    selected_anncs: List[dict]  # ë¹„êµìš© ë‹¤ì¤‘ ì„ íƒ
    retrieved_docs: List[dict]
    # ì¶œë ¥
    answer: str
    debug_info: dict


# =============================================================================
# ìœ í‹¸ë¦¬í‹°
# =============================================================================
def get_embedding(text: str) -> List[float]:
    resp = client.embeddings.create(input=text, model=ChatbotConfig.EMBEDDING_MODEL)
    return resp.data[0].embedding


def call_llm(system: str, user: str, json_mode: bool = False, temp: float = 0) -> str:
    kwargs = {
        "model": ChatbotConfig.LLM_MODEL,
        "messages": [{"role": "system", "content": system}, {"role": "user", "content": user}],
        "temperature": temp
    }
    if json_mode:
        kwargs["response_format"] = {"type": "json_object"}
    return client.chat.completions.create(**kwargs).choices[0].message.content


def calculate_dday(deadline: str) -> str:
    if not deadline:
        return ""
    try:
        cleaned = re.sub(r'[ë…„ì›”ì¼\s]', '-', deadline).replace('.', '-').replace('--', '-').strip('-')
        m = re.search(r'(\d{2,4})-?(\d{1,2})-?(\d{1,2})', cleaned)
        if not m:
            return ""
        y, mo, d = m.groups()
        if len(y) == 2:
            y = '20' + y
        diff = (date(int(y), int(mo), int(d)) - date.today()).days
        return "ë§ˆê°" if diff < 0 else "D-Day" if diff == 0 else f"D-{diff}"
    except:
        return ""


def format_annc_list(anncs: List[dict], with_url: bool = True) -> str:
    if not anncs:
        return "ê²€ìƒ‰ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
    lines = []
    for i, a in enumerate(anncs, 1):
        dday = calculate_dday(a.get('annc_deadline_dt', ''))
        info = f"ìƒíƒœ: {a.get('annc_status', '')} | ì§€ì—­: {a.get('annc_region', '')}"
        if dday:
            info += f" | {dday}"
        if a.get('annc_deadline_dt'):
            info += f" | ë§ˆê°: {a['annc_deadline_dt']}"
        line = f"{i}. **{a.get('annc_title', '')}**\n   - {info}"
        if with_url and a.get('annc_url'):
            line += f"\n   - [ê³µê³  ë°”ë¡œê°€ê¸°]({a['annc_url']})"
        lines.append(line)
    return "\n".join(lines)


def format_context(chat_history: List[dict], prev_anncs: List[dict], selected: Optional[dict]) -> str:
    parts = []
    if chat_history:
        recent = chat_history[-6:]
        conv = "\n".join([f"{'ì‚¬ìš©ì' if m['role']=='user' else 'ì±—ë´‡'}: {m['content'][:100]}" for m in recent])
        parts.append(f"[ìµœê·¼ ëŒ€í™”]\n{conv}")
    if prev_anncs:
        titles = "\n".join([f"{i}. {a['annc_title'][:40]}" for i, a in enumerate(prev_anncs, 1)])
        parts.append(f"[í˜„ì¬ ê³µê³  ëª©ë¡ ({len(prev_anncs)}ê°œ)]\n{titles}")
    if selected:
        parts.append(f"[ì„ íƒëœ ê³µê³ ]\n{selected['annc_title']}")
    return "\n\n".join(parts) if parts else "ì—†ìŒ"


# =============================================================================
# ë…¸ë“œ 1: ì˜ë„ ë¶„ë¥˜
# =============================================================================
def classify_intent(state: GraphState) -> GraphState:
    question = state["question"]
    context = format_context(
        state.get("chat_history", []),
        state.get("prev_anncs", []),
        state.get("selected_annc")
    )

    # DB ë©”íƒ€ë°ì´í„°
    db_info = {
        "statuses": ChatbotConfig.get("statuses"),
        "regions": ChatbotConfig.get("regions"),
        "dtl_types": ChatbotConfig.get("dtl_types")
    }

    search_history_info = ""
    if state.get("search_history"):
        hist = [f"- {h['query']}" for h in state["search_history"][-3:]]
        search_history_info = f"\n[ì´ì „ ê²€ìƒ‰ ê¸°ë¡]\n" + "\n".join(hist)

    prompt = f"""ì£¼íƒ ê³µê³  ì•ˆë‚´ ì±—ë´‡ì˜ ì˜ë„ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”.

{context}
{search_history_info}

# DB ë©”íƒ€ë°ì´í„° (RDB í•„í„°ë§ ê°€ëŠ¥ ê°’)
- ìƒíƒœê°’: {db_info['statuses']}
- ì§€ì—­(ê´‘ì—­ì‹œ/ë„): {db_info['regions']}
- ìƒì„¸ìœ í˜•: {db_info['dtl_types']}

# ì˜ë„ ë¶„ë¥˜ (5ê°€ì§€) - ìš°ì„ ìˆœìœ„ ìˆœ

## 1. `select` - ëª©ë¡ì—ì„œ ê³µê³  ì„ íƒ (ìµœìš°ì„ )
ì¡°ê±´: prev_anncs(ê²€ìƒ‰ê²°ê³¼ ëª©ë¡)ê°€ ìˆê³ , ë²ˆí˜¸/ìˆœì„œë¡œ íŠ¹ì • ê³µê³ ë¥¼ ì§€ëª©
ì˜ˆì‹œ:
- "1ë²ˆ" / "2ë²ˆ ê³µê³ " / "ì²«ë²ˆì§¸" / "ë‘ë²ˆì§¸êº¼"
- "1ë²ˆ ê³µê³  ì•Œë ¤ì¤˜" / "3ë²ˆ ì„ íƒ"
- "ë§¨ ìœ„ì—êº¼" / "ë§ˆì§€ë§‰ ê³µê³ "
ì£¼ì˜: "1ì¸ê°€êµ¬"ëŠ” selectê°€ ì•„ë‹˜ (ëŒ€ìƒì ê²€ìƒ‰)

## 2. `detail` - ì„ íƒëœ ê³µê³ ì˜ ìƒì„¸ ì •ë³´ ì§ˆë¬¸
ì¡°ê±´: selected_annc(ì„ íƒëœ ê³µê³ )ê°€ ìˆê³ , í•´ë‹¹ ê³µê³ ì˜ ì„¸ë¶€ ì •ë³´ ì§ˆë¬¸
ì˜ˆì‹œ:
- "ì‹ ì²­ìê²©ì´ ë­ì•¼?" / "ìê²©ìš”ê±´ ì•Œë ¤ì¤˜"
- "ë©´ì  ì •ë³´" / "í‰ìˆ˜ê°€ ì–´ë–»ê²Œ ë¼?"
- "ì„ëŒ€ë£Œ" / "ë³´ì¦ê¸ˆ" / "ì›”ì„¸"
- "ì‹ ì²­ê¸°ê°„" / "ì–¸ì œê¹Œì§€ì•¼?" / "ë§ˆê°ì¼"
- "í•„ìš”ì„œë¥˜" / "ì œì¶œì„œë¥˜"
- "ë‹¹ì²¨ì ë°œí‘œì¼" / "ì…ì£¼ì¼"
ì£¼ì˜: ì„ íƒëœ ê³µê³  ì—†ì´ "ì‹ ì²­ìê²©"ë§Œ ë¬¼ìœ¼ë©´ search

## 3. `compare` - ì—¬ëŸ¬ ê³µê³  ë¹„êµ
ì¡°ê±´: prev_anncsê°€ 2ê°œ ì´ìƒì´ê³ , ë¹„êµ ìš”ì²­
ì˜ˆì‹œ:
- "1ë²ˆì´ë‘ 2ë²ˆ ë¹„êµí•´ì¤˜"
- "ì²«ë²ˆì§¸ë‘ ì„¸ë²ˆì§¸ ë­ê°€ ë‹¬ë¼?"
- "ë‘˜ ë‹¤ ë¹„êµ" / "ì „ë¶€ ë¹„êµí•´ì¤˜"

## 4. `search` - ê³µê³  ê²€ìƒ‰ (ì‹ ê·œ/ì¶”ê°€/ë³µì›)
### 4a. ì‹ ê·œ ê²€ìƒ‰ (search_mode: "new")
- ìƒˆë¡œìš´ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰, ê¸°ì¡´ ê²°ê³¼ ëŒ€ì²´
- "ì‹ í˜¼ë¶€ë¶€ ê³µê³  ì•Œë ¤ì¤˜" / "ì²­ë…„ ëŒ€ìƒ ê³µê³ "
- "ì ‘ìˆ˜ì¤‘ì¸ ê³µê³ " / "ê³µê³ ì¤‘ì¸ ê²ƒë“¤"
- "ê²½ê¸°ë„ í–‰ë³µì£¼íƒ" / "ì„œìš¸ ì„ëŒ€"
- "1ì¸ê°€êµ¬ ê³µê³ " / "ë¬´ì£¼íƒì ëŒ€ìƒ"

### 4b. ì¶”ê°€ ê²€ìƒ‰ (search_mode: "add")
- ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ì— ì¶”ê°€ (prev_anncs ìœ ì§€)
- "~ë„ ë³´ì—¬ì¤˜" / "~ë„ ì¶”ê°€í•´ì¤˜" / "~ë„ í¬í•¨"
- "ê²½ê¸°ë„ë„ ë³´ì—¬ì¤˜" / "ê³µê³ ì¤‘ì¸ ê²ƒë„"
- "ì˜êµ¬ì„ëŒ€ë„ ì¶”ê°€" / "ì„œìš¸ë„ í¬í•¨í•´ì„œ"

### 4c. ë³µì› ê²€ìƒ‰ (search_mode: "restore")
- ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë‹¤ì‹œ ë³´ê¸° (search_history í•„ìš”)
- "ì•„ê¹Œ ê²€ìƒ‰í•œê±°" / "ì´ì „ ê²°ê³¼"
- "ì•„ê¹Œ ì‹ í˜¼ë¶€ë¶€ ê³µê³  ë‹¤ì‹œ" / "ë°©ê¸ˆ ì „ ê²€ìƒ‰"

### RDB í•„í„° ì¶”ì¶œ ê·œì¹™
- annc_status: "ì ‘ìˆ˜ì¤‘", "ê³µê³ ì¤‘" ë“± ìƒíƒœ ì–¸ê¸‰ ì‹œ
- annc_dtl_type: "í–‰ë³µì£¼íƒ", "ì˜êµ¬ì„ëŒ€", "ë§¤ì…ì„ëŒ€" ë“± ìœ í˜• ì–¸ê¸‰ ì‹œ
- rag_keywords: ëŒ€ìƒì(ì‹ í˜¼ë¶€ë¶€, ì²­ë…„, 1ì¸), ì§€ì—­(ìˆ˜ì›, ì„œëŒ€ë¬¸), ê¸°íƒ€ í‚¤ì›Œë“œ

## 5. `chat` - ì¼ë°˜ ëŒ€í™”/ì œë„ ì„¤ëª…
ì¡°ê±´: ìœ„ ì˜ë„ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì¼ë°˜ ì§ˆë¬¸
ì˜ˆì‹œ:
- ì¸ì‚¬: "ì•ˆë…•" / "ê³ ë§ˆì›Œ" / "ë„ì›€ì´ ëì–´"
- ì œë„ ì„¤ëª…: "í–‰ë³µì£¼íƒì´ ë­ì•¼?" / "LHê°€ ë­ì•¼?" / "ê³µê³µì„ëŒ€ë€?"
- ì¼ë°˜ ì§ˆë¬¸: "ì²­ì•½ ìê²©ìš”ê±´" / "ì£¼íƒì²­ì•½ ë°©ë²•"
- ìµœì‹  ì •ë³´: "2025ë…„ ì²­ì•½ ì •ì±…" (needs_web_search: true)

needs_web_search: trueì¸ ê²½ìš°
- ìµœì‹  ì •ì±…/ì œë„ ë³€ê²½ ì§ˆë¬¸
- êµ¬ì²´ì  í†µê³„/ê²½ìŸë¥  ì§ˆë¬¸
- LLM ì§€ì‹ìœ¼ë¡œ ë‹µí•˜ê¸° ì–´ë ¤ìš´ ì‹¤ì‹œê°„ ì •ë³´

# íŒë‹¨ ê·œì¹™
1. ìˆ«ì+"ë²ˆ"ì€ select, ìˆ«ì+"ì¸"ì€ ëŒ€ìƒì(search)
2. selected_annc ì—†ì´ ìƒì„¸ì§ˆë¬¸ â†’ searchë¡œ ì „í™˜
3. "~ë„"ê°€ ë¶™ìœ¼ë©´ add ëª¨ë“œ ê²€í† 
4. ì• ë§¤í•˜ë©´ search (ì‹ ê·œ)ë¡œ ë¶„ë¥˜

# ì‘ë‹µ í˜•ì‹ (JSONë§Œ ì¶œë ¥)
{{
  "intent": "search|select|detail|compare|chat",
  "search_mode": "new|add|restore",
  "restore_query": null,
  "select_indices": [],  // 1ë¶€í„° ì‹œì‘! "1ë²ˆ"â†’[1], "2ë²ˆ"â†’[2], "1ë²ˆì´ë‘ 3ë²ˆ"â†’[1,3]
  "rdb_filters": {{
    "annc_status": null,
    "annc_dtl_type": null
  }},
  "rag_keywords": null,
  "needs_web_search": false,
  "reasoning": "íŒë‹¨ ê·¼ê±° í•œ ì¤„"
}}

# select_indices ì£¼ì˜ì‚¬í•­
- 1-indexed: "1ë²ˆ"ì€ [1], "ì²«ë²ˆì§¸"ëŠ” [1]
- "ë§ˆì§€ë§‰"ì€ [-1]
- ì ˆëŒ€ 0ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ"""

    result_str = call_llm(prompt, f"ì§ˆë¬¸: {question}", json_mode=True)

    try:
        result = json.loads(result_str)
        intent = result.get("intent", Intent.CHAT)

        # ê²€ì¦ ë° ë³´ì •
        prev_anncs = state.get("prev_anncs", [])
        selected = state.get("selected_annc")
        rag_keywords = result.get("rag_keywords", "")

        # ìƒì„¸ ì§ˆë¬¸ í‚¤ì›Œë“œ íŒ¨í„´
        detail_keywords = ['ì‹ ì²­ìê²©', 'ìê²©', 'ë©´ì ', 'í‰ìˆ˜', 'ì„ëŒ€ë£Œ', 'ë³´ì¦ê¸ˆ', 'ì›”ì„¸',
                          'ì‹ ì²­ê¸°ê°„', 'ë§ˆê°', 'ì„œë¥˜', 'ì…ì£¼', 'ë‹¹ì²¨', 'ì†Œë“', 'ìì‚°']

        # 1. selected_anncê°€ ìˆê³  ìƒì„¸ ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ â†’ detailë¡œ ë³´ì •
        if selected and intent == Intent.SEARCH:
            question_lower = question.lower()
            if any(kw in question_lower for kw in detail_keywords):
                intent = Intent.DETAIL
                result["intent"] = Intent.DETAIL

        # 2. selectì¸ë° ëª©ë¡ ì—†ìœ¼ë©´ â†’ search
        if intent == Intent.SELECT and not prev_anncs:
            intent = Intent.SEARCH

        # 3. detailì¸ë° ì„ íƒ ì—†ê³  ëª©ë¡ë„ ì—†ìœ¼ë©´ â†’ search
        if intent == Intent.DETAIL and not selected and not prev_anncs:
            intent = Intent.SEARCH

        # 4. compareì¸ë° ëª©ë¡ ë¶€ì¡± â†’ search
        if intent == Intent.COMPARE and len(prev_anncs) < 2:
            intent = Intent.SEARCH

        return {
            "intent": intent,
            "intent_data": result,
            "debug_info": {"intent_result": result}
        }
    except Exception as e:
        return {
            "intent": Intent.CHAT,
            "intent_data": {"error": str(e)},
            "debug_info": {"error": str(e)}
        }


# =============================================================================
# ë…¸ë“œ 2: ê²€ìƒ‰ (RDB í•„í„° + RAG)
# =============================================================================
def expand_query(question: str) -> str:
    prompt = """ì£¼íƒ ê³µê³  RAG ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ í™•ì¥ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ê´€ë ¨ ë™ì˜ì–´/ìœ ì˜ì–´ë¡œ í™•ì¥í•©ë‹ˆë‹¤.

# ëŒ€ìƒì ê´€ë ¨ ë™ì˜ì–´
- ì‹ í˜¼ë¶€ë¶€ â†’ ì‹ í˜¼ë¶€ë¶€, í˜¼ì¸, ì˜ˆë¹„ì‹ í˜¼ë¶€ë¶€, ì‹ í˜¼í¬ë§íƒ€ìš´, í˜¼ì¸ì‹ ê³ , ê²°í˜¼ì˜ˆì •
- ì²­ë…„ â†’ ì²­ë…„, ëŒ€í•™ìƒ, ì‚¬íšŒì´ˆë…„ìƒ, ë§Œ19ì„¸, ë§Œ39ì„¸, ì²­ë…„ê³„ì¸µ
- 1ì¸ê°€êµ¬ â†’ 1ì¸, ë‹¨ë…ì„¸ëŒ€, ë…ì‹ , 1ì¸ì„¸ëŒ€
- ê³ ë ¹ì/ë…¸ì¸ â†’ ê³ ë ¹ì, ì£¼ê±°ì•½ì, ë…¸ì¸, ë§Œ65ì„¸, ê³ ë ¹ìê³„ì¸µ
- ì €ì†Œë“ì¸µ â†’ ì €ì†Œë“, ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì, ì°¨ìƒìœ„ê³„ì¸µ, ì†Œë“ê¸°ì¤€
- ë‹¤ìë…€ â†’ ë‹¤ìë…€, 3ìë…€, ë¯¸ì„±ë…„ìë…€, ìë…€ìˆ˜

# ìê²©ìš”ê±´ ê´€ë ¨
- ì‹ ì²­ìê²© â†’ ì‹ ì²­ìê²©, ì…ì£¼ìê²©, ê³µê¸‰ëŒ€ìƒ, ìê²©ìš”ê±´, ì‹ ì²­ëŒ€ìƒ, ì…ì£¼ëŒ€ìƒì
- ë¬´ì£¼íƒ â†’ ë¬´ì£¼íƒ, ë¬´ì£¼íƒì„¸ëŒ€êµ¬ì„±ì›, ë¬´ì£¼íƒìš”ê±´, ì£¼íƒì†Œìœ ì—¬ë¶€
- ì†Œë“ê¸°ì¤€ â†’ ì†Œë“ê¸°ì¤€, ì›”í‰ê· ì†Œë“, ë„ì‹œê·¼ë¡œì, ì†Œë“ìš”ê±´, ìì‚°ê¸°ì¤€
- ìì‚°ê¸°ì¤€ â†’ ìì‚°, ë¶€ë™ì‚°, ìë™ì°¨, ê¸ˆìœµìì‚°, ìì‚°ë³´ìœ 

# ì£¼íƒì •ë³´ ê´€ë ¨
- ë©´ì  â†’ ë©´ì , ì „ìš©ë©´ì , ì£¼ê±°ì „ìš©, ê³µê¸‰ë©´ì , ê³„ì•½ë©´ì , í‰í˜•, í‰ìˆ˜, ã¡
- ì„ëŒ€ë£Œ â†’ ì„ëŒ€ë£Œ, ë³´ì¦ê¸ˆ, ì›”ì„ëŒ€ë£Œ, ì›”ì„¸, ì„ëŒ€ì¡°ê±´, ë‚©ë¶€ê¸ˆì•¡
- ìœ„ì¹˜ â†’ ìœ„ì¹˜, ì†Œì¬ì§€, ì£¼ì†Œ, ë‹¨ì§€, ë¸”ë¡, ë™, í˜¸

# ì¼ì • ê´€ë ¨
- ì‹ ì²­ê¸°ê°„ â†’ ì‹ ì²­ê¸°ê°„, ì ‘ìˆ˜ê¸°ê°„, ëª¨ì§‘ê¸°ê°„, ì²­ì•½ì¼ì •, ì‹ ì²­ì¼
- ë§ˆê° â†’ ë§ˆê°ì¼, ì ‘ìˆ˜ë§ˆê°, ëª¨ì§‘ë§ˆê°, ê³µê³ ê¸°í•œ
- ì…ì£¼ â†’ ì…ì£¼ì˜ˆì •, ì…ì£¼ì¼, ì…ì£¼ì‹œê¸°, ê³„ì•½ì²´ê²°

# ì„œë¥˜ ê´€ë ¨
- ì„œë¥˜ â†’ ì œì¶œì„œë¥˜, êµ¬ë¹„ì„œë¥˜, í•„ìš”ì„œë¥˜, ì¦ë¹™ì„œë¥˜, ì²¨ë¶€ì„œë¥˜
- ì‹ ì²­ë°©ë²• â†’ ì‹ ì²­ë°©ë²•, ì ‘ìˆ˜ë°©ë²•, ì²­ì•½ë°©ë²•, ì¸í„°ë„·ì²­ì•½

# ê·œì¹™
1. ì›ë³¸ ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œ ìœ ì§€
2. ìœ„ ë™ì˜ì–´ ëª©ë¡ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
3. ë¶ˆí•„ìš”í•œ ì¡°ì‚¬/ì–´ë¯¸ ì œê±° (ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼, ì˜ ë“±)
4. ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥
5. ìµœëŒ€ 20ê°œ í‚¤ì›Œë“œ

# ì¶œë ¥ í˜•ì‹
í‚¤ì›Œë“œ1 í‚¤ì›Œë“œ2 í‚¤ì›Œë“œ3 ... (ê³µë°± êµ¬ë¶„, í‚¤ì›Œë“œë§Œ)"""
    return call_llm(prompt, f"ì§ˆë¬¸: {question}", temp=0).strip()


def search_announcements(state: GraphState) -> GraphState:
    intent_data = state.get("intent_data", {})
    question = state["question"]
    search_mode = intent_data.get("search_mode", "new")

    # ë³µì› ëª¨ë“œ
    if search_mode == "restore":
        restore_query = intent_data.get("restore_query", "")
        for hist in reversed(state.get("search_history", [])):
            if restore_query.lower() in hist["query"].lower():
                return {
                    "prev_anncs": hist["anncs"],
                    "selected_annc": None,
                    "answer": f"ì´ì „ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n\n{format_annc_list(hist['anncs'])}"
                }
        # ëª»ì°¾ìœ¼ë©´ ìƒˆë¡œ ê²€ìƒ‰
        search_mode = "new"

    # RDB í•„í„°
    rdb_filters = intent_data.get("rdb_filters", {})
    annc_status = rdb_filters.get("annc_status")
    annc_dtl_type = rdb_filters.get("annc_dtl_type")

    # RDBì—ì„œ í›„ë³´ ê³µê³  ê°€ì ¸ì˜¤ê¸°
    from .models import AnncAll
    queryset = AnncAll.objects.filter(service_status='OPEN')
    if annc_status:
        queryset = queryset.filter(annc_status=annc_status)
    if annc_dtl_type:
        queryset = queryset.filter(annc_dtl_type__icontains=annc_dtl_type)

    candidate_ids = list(queryset.values_list('annc_id', flat=True))

    # RAG ê²€ìƒ‰
    rag_keywords = intent_data.get("rag_keywords") or question
    expanded = expand_query(rag_keywords)
    embedding = get_embedding(expanded)

    docs = DocChunkService.hybrid_search(
        query_text=expanded,
        query_embedding=embedding,
        top_k=ChatbotConfig.RAG_TOP_K,
        annc_id_filter=candidate_ids if candidate_ids else None
    )

    # ê²€ìƒ‰ëœ ì²­í¬ì—ì„œ ê³µê³  ì¶”ì¶œ
    seen = set()
    annc_ids = []
    for doc in docs:
        aid = doc.get('annc_id')
        if aid and aid not in seen:
            seen.add(aid)
            annc_ids.append(aid)

    # ê³µê³  ì •ë³´ ì¡°íšŒ
    new_anncs = []
    if annc_ids:
        anncs = AnncAllService.get_announcements_by_ids(annc_ids)
        annc_map = {a['annc_id']: a for a in anncs}
        for aid in annc_ids:
            if aid in annc_map:
                a = annc_map[aid]
                new_anncs.append({
                    "annc_id": a["annc_id"],
                    "annc_title": a["annc_title"],
                    "annc_status": a.get("annc_status", ""),
                    "annc_region": a.get("annc_region", ""),
                    "annc_deadline_dt": a.get("annc_deadline_dt", ""),
                    "annc_url": a.get("annc_url", ""),
                    "annc_dtl_type": a.get("annc_dtl_type", ""),
                })

    # ì¶”ê°€ ëª¨ë“œ: ê¸°ì¡´ + ìƒˆ ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±°)
    if search_mode == "add":
        existing = state.get("prev_anncs", [])
        existing_ids = {a["annc_id"] for a in existing}
        for a in new_anncs:
            if a["annc_id"] not in existing_ids:
                existing.append(a)
        new_anncs = existing

    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì €ì¥
    search_history = state.get("search_history", []).copy()
    search_history.append({
        "query": question,
        "anncs": new_anncs,
        "timestamp": time.time()
    })
    if len(search_history) > ChatbotConfig.MAX_SEARCH_HISTORY:
        search_history = search_history[-ChatbotConfig.MAX_SEARCH_HISTORY:]

    return {
        "prev_anncs": new_anncs,
        "selected_annc": None,
        "search_history": search_history,
        "retrieved_docs": docs,
        "debug_info": {
            **state.get("debug_info", {}),
            "expanded_query": expanded,
            "rdb_filters": rdb_filters,
            "search_mode": search_mode
        }
    }


# =============================================================================
# ë…¸ë“œ 3: ì„ íƒ
# =============================================================================
def select_announcement(state: GraphState) -> GraphState:
    intent_data = state.get("intent_data", {})
    indices = intent_data.get("select_indices", [1])
    prev_anncs = state.get("prev_anncs", [])

    if not indices:
        indices = [1]

    idx = indices[0]

    # 0-indexedë¡œ ì˜¨ ê²½ìš° ë³´ì • (LLMì´ ê°€ë” 0ë¶€í„° ì‹œì‘)
    if idx == 0:
        idx = 1
    # ë§ˆì§€ë§‰ ì„ íƒ
    if idx == -1:
        idx = len(prev_anncs)

    if 1 <= idx <= len(prev_anncs):
        selected = prev_anncs[idx - 1]
        return {
            "selected_annc": selected,
            "selected_anncs": [selected],
            "debug_info": {**state.get("debug_info", {}), "selected_index": idx}
        }
    else:
        return {
            "answer": f"{idx}ë²ˆ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤. 1~{len(prev_anncs)}ë²ˆ ì¤‘ ì„ íƒí•´ì£¼ì„¸ìš”."
        }


# =============================================================================
# ë…¸ë“œ 4: ìƒì„¸ ê²€ìƒ‰ (RAG)
# =============================================================================
def retrieve_details(state: GraphState) -> GraphState:
    question = state["question"]
    selected = state.get("selected_annc")

    if not selected:
        prev_anncs = state.get("prev_anncs", [])
        if len(prev_anncs) == 1:
            selected = prev_anncs[0]
        else:
            return {"answer": "ë¨¼ì € ê³µê³ ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."}

    expanded = expand_query(question)
    embedding = get_embedding(expanded)

    # ìƒì„¸ ì§ˆë¬¸ì€ ë” ë§ì€ ì²­í¬ í•„ìš” (ì—¬ëŸ¬ ë‹¨ì§€ ì •ë³´ í¬í•¨)
    detail_top_k = ChatbotConfig.RAG_TOP_K + 10  # 25ê°œ

    docs = DocChunkService.hybrid_search(
        query_text=expanded,
        query_embedding=embedding,
        top_k=detail_top_k,
        annc_id_filter=[selected["annc_id"]]
    )

    # ë©´ì /ì„ëŒ€ë£Œ ì§ˆë¬¸ ì‹œ í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì²­í¬ ë³´ê°•
    table_keywords = ['ë©´ì ', 'ì„ëŒ€ë£Œ', 'ë³´ì¦ê¸ˆ', 'ì›”ì„¸', 'ê³„ì•½ë©´ì ', 'ì „ìš©ë©´ì ', 'í‰ìˆ˜']
    if any(kw in question for kw in table_keywords):
        from .models import DocChunks
        from django.db.models import Q

        # í•´ë‹¹ ê³µê³ ì˜ ë©´ì /ì„ëŒ€ë£Œ ê´€ë ¨ í…Œì´ë¸” ì²­í¬ ì§ì ‘ ì¡°íšŒ
        # 1ìˆœìœ„: ê³„ì•½ë©´ì , ì „ìš©ë©´ì  ë“± ë©´ì  í‚¤ì›Œë“œ í¬í•¨ ì²­í¬
        # 2ìˆœìœ„: ë‹¨ì§€ëª… + ìˆ«ì íŒ¨í„´ì´ ìˆëŠ” í…Œì´ë¸” ì²­í¬
        extra_chunks = DocChunks.objects.filter(
            annc_id=selected["annc_id"]
        ).filter(
            Q(chunk_text__contains='ê³„ì•½ë©´ì ') |
            Q(chunk_text__contains='ì „ìš©ë©´ì ') |
            Q(chunk_text__contains='ì£¼ê±°ì „ìš©') |
            Q(chunk_text__contains='ì„ëŒ€ë³´ì¦ê¸ˆ') |
            Q(chunk_text__contains='ì›”ì„ëŒ€ë£Œ') |
            Q(chunk_text__contains='ê³µê¸‰í˜•ë³„') |
            Q(chunk_text__contains='ê³µê¸‰ëŒ€ìƒ') |
            # ë‹¨ì§€ë³„ ë©´ì  í…Œì´ë¸” íŒ¨í„´
            (Q(chunk_type='table') & (
                Q(chunk_text__contains='16A') |
                Q(chunk_text__contains='26B') |
                Q(chunk_text__contains='36') |
                Q(chunk_text__contains='46') |
                Q(chunk_text__contains='ã¡')
            ))
        ).order_by('page_num').values('chunk_id', 'chunk_text', 'chunk_type', 'page_num', 'annc_id', 'file_id')

        # ê¸°ì¡´ docsì— ì—†ëŠ” ì²­í¬ë§Œ ì¶”ê°€ (ì•ìª½ì— ì¶”ê°€í•˜ì—¬ ìš°ì„ ìˆœìœ„ ë†’ì„)
        existing_ids = {d.get('chunk_id') for d in docs}
        extra_list = []
        for chunk in extra_chunks:
            if chunk['chunk_id'] not in existing_ids:
                extra_list.append(dict(chunk))

        # ë©´ì  ê´€ë ¨ ì²­í¬ë¥¼ ì•ì— ë°°ì¹˜ (í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ)
        docs = extra_list + docs

    return {
        "selected_annc": selected,
        "retrieved_docs": docs,
        "debug_info": {
            **state.get("debug_info", {}),
            "expanded_query": expanded,
            "retrieved_count": len(docs)
        }
    }


# =============================================================================
# ë…¸ë“œ 5: ë¹„êµ
# =============================================================================
def compare_announcements(state: GraphState) -> GraphState:
    intent_data = state.get("intent_data", {})
    indices = intent_data.get("select_indices", [1, 2])
    prev_anncs = state.get("prev_anncs", [])

    selected_anncs = []
    for idx in indices:
        if 1 <= idx <= len(prev_anncs):
            selected_anncs.append(prev_anncs[idx - 1])

    if len(selected_anncs) < 2:
        return {"answer": "ë¹„êµí•  ê³µê³ ë¥¼ 2ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”."}

    # ê° ê³µê³ ë³„ RAG ê²€ìƒ‰
    all_docs = []
    for annc in selected_anncs:
        docs = DocChunkService.hybrid_search(
            query_text="ì‹ ì²­ìê²© ì„ëŒ€ë£Œ ë©´ì  ì‹ ì²­ê¸°ê°„",
            query_embedding=get_embedding("ì‹ ì²­ìê²© ì„ëŒ€ë£Œ ë©´ì  ì‹ ì²­ê¸°ê°„"),
            top_k=5,
            annc_id_filter=[annc["annc_id"]]
        )
        all_docs.extend(docs)

    return {
        "selected_anncs": selected_anncs,
        "retrieved_docs": all_docs,
        "debug_info": {**state.get("debug_info", {}), "compare_count": len(selected_anncs)}
    }


# =============================================================================
# ë…¸ë“œ 6: ì¼ë°˜ ëŒ€í™” / ì›¹ ê²€ìƒ‰
# =============================================================================
def general_chat(state: GraphState) -> GraphState:
    question = state["question"]
    intent_data = state.get("intent_data", {})
    needs_web = intent_data.get("needs_web_search", False)

    web_context = ""
    if needs_web and TAVILY_AVAILABLE:
        try:
            result = tavily_client.search(query=question, max_results=3)
            if result.get("results"):
                web_context = "\n\n[ì›¹ ê²€ìƒ‰ ê²°ê³¼ - ìµœì‹  ì •ë³´]\n"
                for r in result["results"][:3]:
                    web_context += f"- **{r.get('title', '')}**: {r.get('content', '')[:200]}\n"
                web_context += "\nìœ„ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
        except:
            pass

    prompt = f"""ì£¼íƒ ê³µê³  ì•ˆë‚´ ì „ë¬¸ ì±—ë´‡ 'ì§‘í•(ZIP-FIT)'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì£¼íƒ/ì„ëŒ€/ì²­ì•½ ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

# ì±—ë´‡ ê¸°ëŠ¥ ì†Œê°œ
1. **ê³µê³  ê²€ìƒ‰**: ì§€ì—­, ëŒ€ìƒì(ì‹ í˜¼ë¶€ë¶€/ì²­ë…„/ê³ ë ¹ì ë“±), ìƒíƒœ(ì ‘ìˆ˜ì¤‘/ê³µê³ ì¤‘)ë³„ ê²€ìƒ‰
2. **ìƒì„¸ ì •ë³´ ì•ˆë‚´**: ì‹ ì²­ìê²©, ë©´ì , ì„ëŒ€ë£Œ, ì‹ ì²­ê¸°ê°„, í•„ìš”ì„œë¥˜ ë“±
3. **ê³µê³  ë¹„êµ**: ì—¬ëŸ¬ ê³µê³ ì˜ ì¡°ê±´ ë¹„êµ ë¶„ì„
4. **ì œë„ ì„¤ëª…**: í–‰ë³µì£¼íƒ, ì˜êµ¬ì„ëŒ€, ë§¤ì…ì„ëŒ€ ë“± ì£¼íƒ ì œë„ ì•ˆë‚´

# í˜„ì¬ ì„œë¹„ìŠ¤ ì •ë³´
- ê²€ìƒ‰ ê°€ëŠ¥ ì§€ì—­: {ChatbotConfig.get('regions')}
- ê³µê³  ìœ í˜•: {ChatbotConfig.get('dtl_types')}
- ê³µê³  ìƒíƒœ: {ChatbotConfig.get('statuses')}
{web_context}

# ì‘ë‹µ ê°€ì´ë“œ

## ì¸ì‚¬/ê°ì‚¬ í‘œí˜„
- ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ ì‘ëŒ€
- ì¶”ê°€ ë„ì›€ ì œì•ˆ ("ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?")

## ì£¼íƒ ì œë„ ì„¤ëª… ì§ˆë¬¸
í–‰ë³µì£¼íƒ, ì˜êµ¬ì„ëŒ€, ë§¤ì…ì„ëŒ€, ê³µê³µì„ëŒ€ ë“±ì˜ ì œë„ ì§ˆë¬¸ì—ëŠ”:
- ì •ì˜ì™€ ëª©ì 
- ì£¼ìš” ëŒ€ìƒì
- íŠ¹ì§•/ì¥ì 
- ì‹ ì²­ ë°©ë²• ê°œìš”

## ì²­ì•½/ìê²© ì¼ë°˜ ì§ˆë¬¸
- ì¼ë°˜ì ì¸ ìê²©ìš”ê±´ ì„¤ëª…
- êµ¬ì²´ì ì¸ ì •ë³´ëŠ” "ê³µê³  ê²€ìƒ‰ í›„ í™•ì¸" ì•ˆë‚´
- ì˜ˆ: "ì‹ í˜¼ë¶€ë¶€ ê³µê³  ê²€ìƒ‰í•´ì¤˜"ë¡œ ê²€ìƒ‰ ìœ ë„

## LH/SH ë“± ê¸°ê´€ ì§ˆë¬¸
- ê¸°ê´€ ì†Œê°œ ë° ì—­í• 
- ì£¼ìš” ì‚¬ì—… ì„¤ëª…
- ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ì•ˆë‚´

## ìµœì‹  ì •ì±…/ì œë„ ë³€ê²½ ì§ˆë¬¸
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì •ë³´ ê¸°ë°˜ ë‹µë³€
- ì—†ìœ¼ë©´: "ìµœì‹  ì •ì±…ì€ LH ë˜ëŠ” êµ­í† êµí†µë¶€ í™ˆí˜ì´ì§€ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."

## ì„œë¹„ìŠ¤ ë²”ìœ„ ì™¸ ì§ˆë¬¸
- ì •ì¤‘íˆ ë²”ìœ„ ì™¸ì„ì„ ì•Œë¦¼
- ê°€ëŠ¥í•œ ëŒ€ì•ˆ ì œì‹œ (ì˜ˆ: ê´€ë ¨ ê¸°ê´€ ì•ˆë‚´)

# ì‘ë‹µ ìŠ¤íƒ€ì¼
- ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë‹µë³€
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ìì œ
- í•„ìš”ì‹œ ë§ˆí¬ë‹¤ìš´ í™œìš©"""

    messages = [{"role": "system", "content": prompt}]
    messages.extend(state.get("chat_history", [])[-6:])
    messages.append({"role": "user", "content": question})

    resp = client.chat.completions.create(
        model=ChatbotConfig.LLM_MODEL,
        messages=messages,
        temperature=0.7
    )
    return {"answer": resp.choices[0].message.content}


# =============================================================================
# ì‘ë‹µ ìƒì„±
# =============================================================================
def generate_search_response(state: GraphState) -> GraphState:
    question = state["question"]
    anncs = state.get("prev_anncs", [])
    docs = state.get("retrieved_docs", [])

    if not anncs:
        return {"answer": "ì¡°ê±´ì— ë§ëŠ” ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."}

    context = "\n".join([f"[ê³µê³ :{d.get('annc_id')}, p{d.get('page_num')}] {d.get('chunk_text', '')[:200]}" for d in docs[:8]])

    prompt = f"""ì£¼íƒ ê³µê³  ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.

# ì‚¬ìš©ì ì§ˆë¬¸
{question}

# ê²€ìƒ‰ëœ ê³µê³  ëª©ë¡ (ë²ˆí˜¸ í•„ìˆ˜ ì‚¬ìš©!)
{format_annc_list(anncs, with_url=False)}

# ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© (RAG)
{context}

# ì‘ë‹µ ì‘ì„± ê·œì¹™

## í•„ìˆ˜ ê·œì¹™
1. ë°˜ë“œì‹œ ìœ„ [ê²€ìƒ‰ëœ ê³µê³  ëª©ë¡]ì˜ ë²ˆí˜¸(1ë²ˆ, 2ë²ˆ...)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µê³ ë¥¼ ì–¸ê¸‰í•  ê²ƒ
2. ëª©ë¡ì— ì—†ëŠ” ê³µê³ ëª…ì´ë‚˜ ë²ˆí˜¸ë¥¼ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ
3. ë¬¸ì„œ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ê³µê³ ë¥¼ ì¶”ì²œ

## ì‘ë‹µ êµ¬ì¡°
1. **ì¶”ì²œ ìš”ì•½** (1-2ë¬¸ì¥): ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ê³µê³  ë²ˆí˜¸ì™€ ì´ìœ 
2. **ê°„ë‹¨í•œ ì„¤ëª…** (2-3ë¬¸ì¥): ì™œ í•´ë‹¹ ê³µê³ ê°€ ì í•©í•œì§€ ë¬¸ì„œ ê¸°ë°˜ ì„¤ëª…
3. **ë‹¤ìŒ ì•ˆë‚´**: "Në²ˆ ê³µê³  ì•Œë ¤ì¤˜"ë¡œ ìƒì„¸ ì •ë³´ í™•ì¸ ìœ ë„

## ì‘ë‹µ ìŠ¤íƒ€ì¼
- ì¹œì ˆí•˜ê³  ê°„ê²°í•œ í†¤
- ë¶ˆí•„ìš”í•œ ì„œë¡  ì—†ì´ ë°”ë¡œ ë³¸ë¡ 
- ë§ˆí¬ë‹¤ìš´ ì‚¬ìš© ê°€ëŠ¥ (ë³¼ë“œ, ë¦¬ìŠ¤íŠ¸ ë“±)
- ì „ì²´ 5ë¬¸ì¥ ì´ë‚´"""

    answer = call_llm(prompt, question, temp=0.3)
    answer += "\n\n---\n" + format_annc_list(anncs)
    return {"answer": answer}


def generate_detail_response(state: GraphState) -> GraphState:
    question = state["question"]
    selected = state.get("selected_annc")
    docs = state.get("retrieved_docs", [])

    if not selected:
        return {"answer": "ì„ íƒëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."}

    dday = calculate_dday(selected.get('annc_deadline_dt', ''))
    dday_str = f" ({dday})" if dday else ""

    # ë©´ì /ì„ëŒ€ë£Œ ì§ˆë¬¸ì€ ë” ë§ì€ ì²­í¬ í•„ìš” (ì—¬ëŸ¬ ë‹¨ì§€ ì •ë³´ í¬í•¨)
    table_keywords = ['ë©´ì ', 'ì„ëŒ€ë£Œ', 'ë³´ì¦ê¸ˆ', 'ì›”ì„¸', 'í‰ìˆ˜']
    if any(kw in question for kw in table_keywords):
        max_chunks = 20  # ë©´ì /ì„ëŒ€ë£Œ ì§ˆë¬¸ì€ ë” ë§ì€ ì²­í¬
    else:
        max_chunks = 12

    context = "\n\n".join([f"[p{d.get('page_num', '?')}]\n{d.get('chunk_text', '')}" for d in docs[:max_chunks]])

    prompt = f"""ì£¼íƒ ê³µê³ ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.

# ì‚¬ìš©ì ì§ˆë¬¸
{question}

# í˜„ì¬ ì„ íƒëœ ê³µê³ 
- ì œëª©: {selected.get('annc_title')}
- ìƒíƒœ: {selected.get('annc_status')}
- ì§€ì—­: {selected.get('annc_region')}
- ë§ˆê°ì¼: {selected.get('annc_deadline_dt', 'ì •ë³´ì—†ìŒ')}{dday_str}
- ìœ í˜•: {selected.get('annc_dtl_type', '')}

# ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©
{context}

# ì‘ë‹µ ì‘ì„± ê·œì¹™

## í•„ìˆ˜ ê·œì¹™
1. **ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€**: ìœ„ [ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©]ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©
2. **ì¶œì²˜ ëª…ì‹œ**: ë‹µë³€ì— í˜ì´ì§€ ë²ˆí˜¸ í¬í•¨ (ì˜ˆ: "p3 ì°¸ì¡°")
3. **ì •ë³´ ì—†ì„ ì‹œ**: "í•´ë‹¹ ì •ë³´ëŠ” ê³µê³ ë¬¸ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³µê³  ì›ë¬¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

## âš ï¸ ê¹¨ì§„ í…Œì´ë¸” ë°ì´í„° í•´ì„ ì§€ì¹¨
PDFì—ì„œ ì¶”ì¶œëœ í‘œ ë°ì´í„°ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ë˜ì–´ ê¹¨ì ¸ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì»¬ëŸ¼ëª…ì´ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ë‰¨ (ì˜ˆ: "ê³µê¸‰\\ní˜•ë³„" â†’ "ê³µê¸‰í˜•ë³„", "ì „ìš©\\në©´ì " â†’ "ì „ìš©ë©´ì ")
- ë°ì´í„°ì™€ í—¤ë”ê°€ ë¶„ë¦¬ë¨
- êµ¬ë¶„ì„ (---|---)ê³¼ ì‹¤ì œ ë°ì´í„° í˜¼ì¬

**í•´ì„ ë°©ë²•**:
1. í‘œì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê³  í—¤ë”ì™€ ë°ì´í„°ë¥¼ ë§¤ì¹­
2. ë‹¨ì§€ëª…, íƒ€ì…, ë©´ì  ìˆ«ìë“¤ì˜ íŒ¨í„´ ì¸ì‹
3. ë¹„ìŠ·í•œ íŒ¨í„´ì˜ í–‰ë“¤ì„ ë¬¶ì–´ì„œ í•´ì„
4. ìˆ«ì ê°’(ë©´ì : 16.95, 26.87 ë“± / ê¸ˆì•¡: 5,000ì²œì› ë“±)ì„ ì •í™•íˆ ì¶”ì¶œ

**ì˜ˆì‹œ í•´ì„**:
- "16A | 16.95 | 5,000 | 50" â†’ 16Aíƒ€ì…, ì „ìš©ë©´ì  16.95ã¡, ë³´ì¦ê¸ˆ 5,000ì²œì›, ì›”ì„¸ 50ì²œì›
- ì—¬ëŸ¬ ë‹¨ì§€ê°€ ë‚˜ì˜¤ë©´ (ì–‘ì£¼ì˜¥ì •3, ì–‘ì£¼ê³ ì, ë™ë‘ì²œì†¡ë‚´ ë“±) ê°ê° êµ¬ë¶„í•˜ì—¬ í‘œì‹œ

## ì§ˆë¬¸ ìœ í˜•ë³„ ë‹µë³€ ê°€ì´ë“œ

### ì‹ ì²­ìê²©/ì…ì£¼ìê²© ì§ˆë¬¸
- ëŒ€ìƒì ìœ í˜•ë³„ ìê²©ìš”ê±´ ì •ë¦¬
- ì†Œë“/ìì‚° ê¸°ì¤€ í¬í•¨
- ë¬´ì£¼íƒ ìš”ê±´ ì„¤ëª…

### ë©´ì /í‰ìˆ˜ ì§ˆë¬¸
- í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬ (ì „ìš©ë©´ì , ê³µê¸‰ë©´ì  ë“±)
- **ì—¬ëŸ¬ ë‹¨ì§€ê°€ ìˆìœ¼ë©´ ë‹¨ì§€ë³„ë¡œ ëª¨ë‘ í‘œì‹œ** (ì˜ˆ: ë™ë‘ì²œ ì†¡ë‚´, ì–‘ì£¼ ê³ ì ë“±)
- íƒ€ì…ë³„(16A, 26B ë“±) êµ¬ë¶„ ëª…ì‹œ
- ã¡ ë‹¨ìœ„ ì‚¬ìš©
- **ê¹¨ì§„ í‘œì—ì„œë„ ìˆ«ì ê°’ë“¤ì„ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ**

### ì„ëŒ€ë£Œ/ë³´ì¦ê¸ˆ ì§ˆë¬¸
- í‘œ í˜•ì‹ ê¶Œì¥ (íƒ€ì…ë³„, ê³„ì¸µë³„)
- **ì—¬ëŸ¬ ë‹¨ì§€ê°€ ìˆìœ¼ë©´ ë‹¨ì§€ë³„ë¡œ ëª¨ë‘ í‘œì‹œ**
- ë³´ì¦ê¸ˆ/ì›”ì„ëŒ€ë£Œ êµ¬ë¶„
- ì „í™˜ë³´ì¦ê¸ˆ ì •ë³´ ìˆìœ¼ë©´ í¬í•¨
- **ë‹¨ìœ„ í‘œê¸° ì£¼ì˜**: ì²œì›/ë§Œì› ë‹¨ìœ„ í™•ì¸

### ì‹ ì²­ê¸°ê°„/ì¼ì • ì§ˆë¬¸
- ë‚ ì§œ ëª…í™•íˆ í‘œê¸°
- ë‹¨ê³„ë³„ ì¼ì • (ì‹ ì²­â†’ë°œí‘œâ†’ê³„ì•½â†’ì…ì£¼) ì •ë¦¬
- ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ì ‘ìˆ˜ êµ¬ë¶„

### ì„œë¥˜/ì‹ ì²­ë°©ë²• ì§ˆë¬¸
- í•„ìš” ì„œë¥˜ ë¦¬ìŠ¤íŠ¸ í˜•ì‹
- ë°œê¸‰ì²˜/ìœ ì˜ì‚¬í•­ í¬í•¨
- ì¸í„°ë„· ì²­ì•½ URL ìˆìœ¼ë©´ ì•ˆë‚´

## ì‘ë‹µ ìŠ¤íƒ€ì¼
- ë§ˆí¬ë‹¤ìš´ í‘œ/ë¦¬ìŠ¤íŠ¸ ì ê·¹ í™œìš©
- ë³µì¡í•œ ì •ë³´ëŠ” êµ¬ì¡°í™”í•˜ì—¬ ê°€ë…ì„± ë†’ì´ê¸°
- í•µì‹¬ ë‚´ìš© ë¨¼ì €, ë¶€ê°€ ì„¤ëª… ë‚˜ì¤‘ì—

## ê¸´ê¸‰ ì•ˆë‚´
- {dday_str}ì´ D-7 ì´ë‚´ë©´: "âš ï¸ ë§ˆê°ì´ ì–¼ë§ˆ ë‚¨ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë‘˜ëŸ¬ ì‹ ì²­í•˜ì„¸ìš”!"
- {dday_str}ì´ D-Day/ë§ˆê°ì´ë©´: "âš ï¸ ì˜¤ëŠ˜ì´ ë§ˆê°ì¼ì…ë‹ˆë‹¤!"""

    answer = call_llm(prompt, question, temp=0.2)
    if selected.get('annc_url'):
        answer += f"\n\nğŸ“ [ê³µê³  ì›ë¬¸ ë°”ë¡œê°€ê¸°]({selected['annc_url']})"
    return {"answer": answer}


def generate_compare_response(state: GraphState) -> GraphState:
    selected_anncs = state.get("selected_anncs", [])
    docs = state.get("retrieved_docs", [])

    if len(selected_anncs) < 2:
        return {"answer": "ë¹„êµí•  ê³µê³ ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}

    annc_info = "\n".join([f"- {a['annc_title']} ({a['annc_region']}, {a['annc_status']})" for a in selected_anncs])
    context = "\n".join([f"[ê³µê³ :{d.get('annc_id')}, p{d.get('page_num')}] {d.get('chunk_text', '')[:300]}" for d in docs[:10]])

    # ê³µê³ ë³„ ìƒì„¸ ì •ë³´ ì •ë¦¬
    annc_details = []
    for a in selected_anncs:
        dday = calculate_dday(a.get('annc_deadline_dt', ''))
        detail = f"""### {a['annc_title']}
- ì§€ì—­: {a.get('annc_region', 'ì •ë³´ì—†ìŒ')}
- ìƒíƒœ: {a.get('annc_status', '')}
- ìœ í˜•: {a.get('annc_dtl_type', '')}
- ë§ˆê°: {a.get('annc_deadline_dt', 'ì •ë³´ì—†ìŒ')} {f'({dday})' if dday else ''}"""
        annc_details.append(detail)

    prompt = f"""ì—¬ëŸ¬ ì£¼íƒ ê³µê³ ë¥¼ ë¹„êµ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.

# ë¹„êµ ëŒ€ìƒ ê³µê³ 
{chr(10).join(annc_details)}

# ê° ê³µê³  ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©
{context}

# ì‘ë‹µ ì‘ì„± ê·œì¹™

## í•„ìˆ˜ ë¹„êµ í•­ëª© (í‘œ í˜•ì‹)
| í•­ëª© | ê³µê³ 1 | ê³µê³ 2 | ... |
|------|-------|-------|-----|
| ì§€ì—­/ìœ„ì¹˜ | | | |
| ëŒ€ìƒì | | | |
| ì‹ ì²­ìê²© | | | |
| ì „ìš©ë©´ì  | | | |
| ì„ëŒ€ì¡°ê±´(ë³´ì¦ê¸ˆ/ì›”ì„¸) | | | |
| ì‹ ì²­ê¸°ê°„/ë§ˆê°ì¼ | | | |

## ì¶”ê°€ ë¶„ì„ ë‚´ìš©
1. **ê° ê³µê³ ì˜ íŠ¹ì§•/ì¥ì ** (2-3ì¤„ì”©)
2. **ì¶”ì²œ ëŒ€ìƒ**
   - "ì‹ í˜¼ë¶€ë¶€ë¼ë©´ â†’ Në²ˆ ê³µê³ "
   - "ì²­ë…„ 1ì¸ ê°€êµ¬ë¼ë©´ â†’ Në²ˆ ê³µê³ "
   - "ì†Œë“ì´ ë‚®ë‹¤ë©´ â†’ Në²ˆ ê³µê³ "
3. **ì£¼ì˜ì‚¬í•­** (ë§ˆê° ì„ë°•, ê²½ìŸë¥  ì˜ˆìƒ ë“±)

## ì‘ë‹µ ìŠ¤íƒ€ì¼
- ê°ê´€ì ì´ê³  ì¤‘ë¦½ì ì¸ ë¹„êµ
- ë§ˆí¬ë‹¤ìš´ í‘œ ì ê·¹ í™œìš©
- ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ í‘œê¸°
- ë§ˆì§€ë§‰ì— "ë” ìì„¸í•œ ì •ë³´ëŠ” 'Në²ˆ ê³µê³  ì•Œë ¤ì¤˜'ë¡œ í™•ì¸í•˜ì„¸ìš”" ì•ˆë‚´"""

    return {"answer": call_llm(prompt, "ë¹„êµ ë¶„ì„í•´ì¤˜", temp=0.3)}


# =============================================================================
# ë¼ìš°í„°
# =============================================================================
def route_intent(state: GraphState) -> str:
    intent = state.get("intent", Intent.CHAT)
    return {
        Intent.SEARCH: "search",
        Intent.SELECT: "select",
        Intent.DETAIL: "detail",
        Intent.COMPARE: "compare",
        Intent.CHAT: "chat"
    }.get(intent, "chat")


def route_after_select(state: GraphState) -> str:
    if state.get("answer"):
        return "end"
    return "detail_retrieve"


# =============================================================================
# ê·¸ë˜í”„ êµ¬ì„±
# =============================================================================
def create_chatbot_graph():
    g = StateGraph(GraphState)

    # ë…¸ë“œ
    g.add_node("classify", classify_intent)
    g.add_node("search", search_announcements)
    g.add_node("select", select_announcement)
    g.add_node("detail_retrieve", retrieve_details)
    g.add_node("compare", compare_announcements)
    g.add_node("chat", general_chat)
    g.add_node("search_response", generate_search_response)
    g.add_node("detail_response", generate_detail_response)
    g.add_node("compare_response", generate_compare_response)

    # ì‹œì‘
    g.set_entry_point("classify")

    # ì˜ë„ë³„ ë¼ìš°íŒ…
    g.add_conditional_edges("classify", route_intent, {
        "search": "search",
        "select": "select",
        "detail": "detail_retrieve",
        "compare": "compare",
        "chat": "chat"
    })

    # ì„ íƒ í›„ ë¼ìš°íŒ…
    g.add_conditional_edges("select", route_after_select, {
        "detail_retrieve": "detail_retrieve",
        "end": END
    })

    # ê³ ì • ì—£ì§€
    g.add_edge("search", "search_response")
    g.add_edge("search_response", END)
    g.add_edge("detail_retrieve", "detail_response")
    g.add_edge("detail_response", END)
    g.add_edge("compare", "compare_response")
    g.add_edge("compare_response", END)
    g.add_edge("chat", END)

    return g.compile()


# =============================================================================
# ì¸í„°í˜ì´ìŠ¤
# =============================================================================
_chatbot = None


def get_chatbot():
    global _chatbot
    if _chatbot is None:
        _chatbot = create_chatbot_graph()
    return _chatbot


def chat(question: str, session_state: dict = None) -> dict:
    session_state = session_state or {}

    initial = {
        "question": question,
        "chat_history": session_state.get("chat_history", []),
        "search_history": session_state.get("search_history", []),
        "prev_anncs": session_state.get("prev_anncs", []),
        "selected_annc": session_state.get("selected_annc"),
        "selected_anncs": [],
        "intent": "",
        "intent_data": {},
        "retrieved_docs": [],
        "answer": "",
        "debug_info": {}
    }

    result = get_chatbot().invoke(initial)

    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    history = session_state.get("chat_history", []).copy()
    history.append({"role": "user", "content": question})
    history.append({"role": "assistant", "content": result.get("answer", "")})

    max_len = ChatbotConfig.MAX_HISTORY_TURNS * 2
    if len(history) > max_len:
        history = history[-max_len:]

    return {
        "answer": result.get("answer", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."),
        "session_state": {
            "chat_history": history,
            "search_history": result.get("search_history", session_state.get("search_history", [])),
            "prev_anncs": result.get("prev_anncs", session_state.get("prev_anncs", [])),
            "selected_annc": result.get("selected_annc", session_state.get("selected_annc"))
        },
        "debug_info": result.get("debug_info", {})
    }
